{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "P3RqeSjHvSml",
        "lOWur2qIvWEs",
        "b_URA2nqwfSN",
        "ze9Wdkkewnjs",
        "72rSEVjAv4xT",
        "4mpMYbSjv8n8",
        "Fm-YSbliv_qV",
        "bA2NtLt-4vA9",
        "MMVdywQg0qyG",
        "itFU4bot0sAU",
        "_YIch0d2w770",
        "J4QqvyVZCMF3",
        "gBEkG7KEClX-",
        "VIoHsv4tCo_5",
        "2NGtO4acC6G5",
        "D7zyCWE7C-Se",
        "KwgC36ytxg2N",
        "IaIatrpWBHQO",
        "fBFRojK9xjml",
        "Rbkk9txRBjx-",
        "axIs-DnpBoJu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CSP"
      ],
      "metadata": {
        "id": "0Az2lFqIvLe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cryptairthmetic"
      ],
      "metadata": {
        "id": "P3RqeSjHvSml"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoWKXWiYvJhA"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import re\n",
        "\n",
        "\n",
        "#Faster Implementation\n",
        "def compile_formula(formula, verbose=False):\n",
        "    formula      = formula.replace(' = ', ' == ')\n",
        "    letters      = cat(sorted(set(re.findall('[A-Z]', formula))))\n",
        "    firstletters = sorted(set(re.findall(r'\\b([A-Z])[A-Z]', formula)))\n",
        "    body         = re.sub('[A-Z]+', compile_word, formula)\n",
        "    body         = ' and '.join(firstletters + [body])\n",
        "    fn = 'lambda {}: {}'.format(','.join(letters), body)\n",
        "    if verbose: print(fn)\n",
        "    assert len(letters) <= 10\n",
        "    return eval(fn), letters\n",
        "\n",
        "def compile_word(matchobj):\n",
        "    word = matchobj.group()\n",
        "    terms = reversed([mult(10**i, L) for (i, L) in enumerate(reversed(word))])\n",
        "    return '(' + '+'.join(terms) + ')'\n",
        "\n",
        "def mult(factor, var): return var if factor == 1 else str(factor) + '*' + var\n",
        "\n",
        "\n",
        "def faster_solve(formula):\n",
        "    fn, letters = compile_formula(formula)\n",
        "    for digits in itertools.permutations((1,2,3,4,5,6,7,8,9,0), len(letters)):\n",
        "        try:\n",
        "            if fn(*digits):\n",
        "                yield formula.translate(str.maketrans(letters, cat(map(str, digits))))\n",
        "        except ArithmeticError: \n",
        "            pass\n",
        "\n",
        "#Standard Solve Implementations\n",
        "def solve(formula):\n",
        "    return filter(valid, letter_replacements(formula))\n",
        "\n",
        "#\n",
        "def letter_replacements(formula):\n",
        "    formula = formula.replace(' = ', ' == ') # Allow = or ==\n",
        "    letters = cat(set(re.findall('[A-Z]', formula)))\n",
        "    for digits in itertools.permutations('1234567890', len(letters)):\n",
        "        yield formula.translate(str.maketrans(letters, cat(digits)))\n",
        "\n",
        "def valid(exp):\n",
        "    try:\n",
        "        return not leading_zero(exp) and eval(exp) is True\n",
        "    except ArithmeticError:\n",
        "        return False\n",
        "    \n",
        "cat = ''.join # Function to concatenate strings\n",
        "    \n",
        "leading_zero = re.compile(r'\\b0[0-9]').search # Function to check for illegal number\n",
        "print(next(faster_solve('SEND + MORE = MONEY')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Coloring Constraint Library"
      ],
      "metadata": {
        "id": "lOWur2qIvWEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from constraint import *\n",
        "\n",
        "def graph_coloring(graph, num_colors):\n",
        "    problem = Problem()\n",
        "\n",
        "    # Create a variable for each vertex and add its domain\n",
        "    for vertex in graph.keys():\n",
        "        problem.addVariable(vertex, range(num_colors))\n",
        "\n",
        "    # Add a constraint for each pair of adjacent vertices\n",
        "    for vertex, neighbors in graph.items():\n",
        "        for neighbor in neighbors:\n",
        "            problem.addConstraint(lambda x, y: x != y, (vertex, neighbor))\n",
        "\n",
        "    # Find a solution that satisfies all constraints\n",
        "    solution = problem.getSolutions()\n",
        "\n",
        "    return solution\n",
        "\n",
        "# Example usage:\n",
        "graph = {\n",
        "    'A': ['B', 'C'],\n",
        "    'B': ['A', 'C', 'D'],\n",
        "    'C': ['A', 'B', 'D'],\n",
        "    'D': ['B', 'C']\n",
        "}\n",
        "num_colors = 3\n",
        "\n",
        "solution = graph_coloring(graph, num_colors)\n",
        "\n",
        "print(solution) # {'A': 0, 'B': 1, 'C': 2, 'D': 0}\n"
      ],
      "metadata": {
        "id": "DWrVp_jvveRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Coloring"
      ],
      "metadata": {
        "id": "b_URA2nqwfSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CSPSolver:\n",
        "    def __init__(self, variables, domains, constraints):\n",
        "        self.variables = variables\n",
        "        self.domains = domains\n",
        "        self.constraints = constraints\n",
        "\n",
        "    def solve(self):\n",
        "        assignment = {}\n",
        "        return self.backtrack_search(assignment)\n",
        "\n",
        "    def backtrack_search(self, assignment):\n",
        "        if len(assignment) == len(self.variables):\n",
        "            return assignment\n",
        "\n",
        "        var = self.select_unassigned_variable(assignment)\n",
        "        for value in self.order_domain_values(var, assignment):\n",
        "            if self.is_consistent(var, value, assignment):\n",
        "                assignment[var] = value\n",
        "                result = self.backtrack_search(assignment)\n",
        "                if result is not None:\n",
        "                    return result\n",
        "                del assignment[var]\n",
        "        return None\n",
        "\n",
        "    def select_unassigned_variable(self, assignment):\n",
        "        unassigned = set(self.variables) - set(assignment.keys())\n",
        "        return min(unassigned, key=lambda var: len(self.domains[var]))\n",
        "\n",
        "    def order_domain_values(self, var, assignment):\n",
        "        return self.domains[var]\n",
        "\n",
        "    def is_consistent(self, var, value, assignment):\n",
        "        assignment[var] = value\n",
        "        for constraint in self.constraints:\n",
        "            if not constraint(assignment):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "\n",
        "# Define variables and domains\n",
        "variables = ['WA', 'NT', 'Q', 'NSW', 'V', 'SA', 'T']\n",
        "domains = {\n",
        "    'WA': ['red', 'green', 'blue'],\n",
        "    'NT': ['red', 'green', 'blue'],\n",
        "    'Q': ['red', 'green', 'blue'],\n",
        "    'NSW': ['red', 'green', 'blue'],\n",
        "    'V': ['red', 'green', 'blue'],\n",
        "    'SA': ['red', 'green', 'blue'],\n",
        "    'T': ['red', 'green', 'blue'],\n",
        "}\n",
        "\n",
        "# Define constraints\n",
        "def adjacent_regions_must_have_different_colors(assignment):\n",
        "    if 'WA' in assignment and 'NT' in assignment:\n",
        "        if assignment['WA'] == assignment['NT']:\n",
        "            return False\n",
        "    # Define similar constraints for other adjacent regions\n",
        "    return True\n",
        "\n",
        "def no_constraint_violations(assignment):\n",
        "    return True\n",
        "\n",
        "constraints = [adjacent_regions_must_have_different_colors, no_constraint_violations]\n",
        "\n",
        "# Create the CSPSolver instance and solve the problem\n",
        "solver = CSPSolver(variables, domains, constraints)\n",
        "solution = solver.solve()\n",
        "print(solution)\n"
      ],
      "metadata": {
        "id": "LSL_QrqVwhn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N Queens"
      ],
      "metadata": {
        "id": "ze9Wdkkewnjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CSPSolver:\n",
        "    def __init__(self, variables, domains, constraints):\n",
        "        self.variables = variables\n",
        "        self.domains = domains\n",
        "        self.constraints = constraints\n",
        "\n",
        "    def solve(self):\n",
        "        assignment = {}\n",
        "        return self.backtrack_search(assignment)\n",
        "\n",
        "    def backtrack_search(self, assignment):\n",
        "        if len(assignment) == len(self.variables):\n",
        "            return assignment\n",
        "\n",
        "        var = self.select_unassigned_variable(assignment)\n",
        "        for value in self.order_domain_values(var, assignment):\n",
        "            if self.is_consistent(var, value, assignment):\n",
        "                assignment[var] = value\n",
        "                result = self.backtrack_search(assignment)\n",
        "                if result is not None:\n",
        "                    return result\n",
        "                del assignment[var]\n",
        "        return None\n",
        "\n",
        "    def select_unassigned_variable(self, assignment):\n",
        "        unassigned = set(self.variables) - set(assignment.keys())\n",
        "        return min(unassigned, key=lambda var: len(self.domains[var]))\n",
        "\n",
        "    def order_domain_values(self, var, assignment):\n",
        "        return self.domains[var]\n",
        "\n",
        "    def is_consistent(self, var, value, assignment):\n",
        "        # Check row and column constraints\n",
        "        if value in assignment.values():\n",
        "            return False\n",
        "        for k, v in assignment.items():\n",
        "            if abs(k - var) == abs(v - value):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "def print_solution(solution):\n",
        "    if solution is None:\n",
        "        print(\"No solution found\")\n",
        "    else:\n",
        "        for i in range(len(solution)):\n",
        "            row = \"\"\n",
        "            for j in range(len(solution)):\n",
        "                if solution[i] == j:\n",
        "                    row += \"Q \"\n",
        "                else:\n",
        "                    row += \". \"\n",
        "            print(row)\n",
        "\n",
        "# Define variables and domains\n",
        "n = 8  # Change n to the desired value of N\n",
        "variables = list(range(n))\n",
        "domains = {i: list(range(n)) for i in range(n)}\n",
        "\n",
        "# Define constraints\n",
        "constraints = []\n",
        "\n",
        "# Create the CSPSolver instance and solve the problem\n",
        "solver = CSPSolver(variables, domains, constraints)\n",
        "solution = solver.solve()\n",
        "print(solution)\n",
        "print_solution(solution)\n"
      ],
      "metadata": {
        "id": "cr4_pB7wwo-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1PhWBRKvw2Gu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Job Scheduling Constraint Libary"
      ],
      "metadata": {
        "id": "72rSEVjAv4xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from constraint import *\n",
        "\n",
        "# Define the job scheduling problem\n",
        "problem = Problem()\n",
        "\n",
        "# Define the variables and domains\n",
        "# Each variable represents a job, and the domain of each variable is the time required to complete the job\n",
        "job1 = [3, 5, 1]\n",
        "job2 = [2, 4, 6]\n",
        "job3 = [4, 3, 2]\n",
        "problem.addVariables([\"job1\", \"job2\", \"job3\"], [job1, job2, job3])\n",
        "\n",
        "# Define the constraints\n",
        "# Each constraint enforces that no two jobs overlap in time\n",
        "for i in range(3):\n",
        "    for j in range(i+1, 3):\n",
        "        problem.addConstraint(lambda j1, j2: j1[i]+j1[j] <= j2[i] or j2[i]+j2[j] <= j1[i], (\"job\"+str(i+1), \"job\"+str(j+1)))\n",
        "\n",
        "# Solve the problem\n",
        "solutions = problem.getSolutions()\n",
        "\n",
        "# Print the solutions\n",
        "for solution in solutions:\n",
        "    print(solution)"
      ],
      "metadata": {
        "id": "csDH6f8LxQ1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TSP Constraint Libary"
      ],
      "metadata": {
        "id": "4mpMYbSjv8n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from constraint import Problem, AllDifferentConstraint\n",
        "\n",
        "# Define the distance matrix between cities\n",
        "distances = [\n",
        "    [0, 10, 15, 20],\n",
        "    [10, 0, 35, 25],\n",
        "    [15, 35, 0, 30],\n",
        "    [20, 25, 30, 0]\n",
        "]\n",
        "\n",
        "# Define the number of cities\n",
        "n = len(distances)\n",
        "\n",
        "# Create a problem instance\n",
        "problem = Problem()\n",
        "\n",
        "# Create variables for the order in which cities are visited\n",
        "order = list(range(n))\n",
        "problem.addVariables(order, range(n))\n",
        "\n",
        "# Add constraint to ensure each city is visited exactly once\n",
        "problem.addConstraint(AllDifferentConstraint(), order)\n",
        "\n",
        "# Define a function to calculate the total distance of a given route\n",
        "def calculate_distance(route):\n",
        "    distance = 0\n",
        "    for i in range(n-1):\n",
        "        distance += distances[route[i]][route[i+1]]\n",
        "    distance += distances[route[n-1]][route[0]]\n",
        "    return distance\n",
        "\n",
        "# Add constraint to minimize the total distance of the route\n",
        "problem.addConstraint(lambda *route: calculate_distance(route), order)\n",
        "\n",
        "# Solve the problem\n",
        "solution = problem.getSolution()\n",
        "\n",
        "# Print the solution\n",
        "print(\"Shortest route:\", [solution[i] for i in range(n)])\n",
        "print(\"Total distance:\", calculate_distance([solution[i] for i in range(n)]))\n"
      ],
      "metadata": {
        "id": "RwqoQEamxXC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Latin Probelm Constraint Library"
      ],
      "metadata": {
        "id": "Fm-YSbliv_qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from constraint import Problem, AllDifferentConstraint\n",
        "\n",
        "# Define the size of the Latin square\n",
        "n = 5\n",
        "\n",
        "# Create a problem instance\n",
        "problem = Problem()\n",
        "\n",
        "# Create variables for each cell in the Latin square\n",
        "variables = []\n",
        "for i in range(n):\n",
        "    for j in range(n):\n",
        "        variables.append((i, j))\n",
        "\n",
        "# Add domain constraints for each variable\n",
        "for variable in variables:\n",
        "    problem.addVariable(variable, range(1, n+1))\n",
        "\n",
        "# Add row constraints\n",
        "for i in range(n):\n",
        "    row_variables = [(i, j) for j in range(n)]\n",
        "    problem.addConstraint(AllDifferentConstraint(), row_variables)\n",
        "\n",
        "# Add column constraints\n",
        "for j in range(n):\n",
        "    column_variables = [(i, j) for i in range(n)]\n",
        "    problem.addConstraint(AllDifferentConstraint(), column_variables)\n",
        "\n",
        "# Add diagonal constraints\n",
        "diagonal1_variables = [(i, i) for i in range(n)]\n",
        "problem.addConstraint(AllDifferentConstraint(), diagonal1_variables)\n",
        "\n",
        "diagonal2_variables = [(i, n-i-1) for i in range(n)]\n",
        "problem.addConstraint(AllDifferentConstraint(), diagonal2_variables)\n",
        "\n",
        "# Solve the problem\n",
        "solutions = problem.getSolutions()\n",
        "\n",
        "# Print the solutions\n",
        "for solution in solutions:\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            print(solution[(i, j)], end=' ')\n",
        "        print()\n",
        "    print()"
      ],
      "metadata": {
        "id": "U9bMsN7c0LKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adversial"
      ],
      "metadata": {
        "id": "R84ZB7puw5yW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tic Tac Toe Min Max"
      ],
      "metadata": {
        "id": "bA2NtLt-4vA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.board = [\" \" for x in range(9)]\n",
        "        self.player = \"X\"\n",
        "\n",
        "    def display_board(self):\n",
        "        row1 = \"| {} | {} | {} |\".format(self.board[0], self.board[1], self.board[2])\n",
        "        row2 = \"| {} | {} | {} |\".format(self.board[3], self.board[4], self.board[5])\n",
        "        row3 = \"| {} | {} | {} |\".format(self.board[6], self.board[7], self.board[8])\n",
        "\n",
        "        print()\n",
        "        print(row1)\n",
        "        print(row2)\n",
        "        print(row3)\n",
        "\n",
        "    def player_move(self):\n",
        "        print(\"Player {} turn.\".format(self.player))\n",
        "        choice = int(input(\"Enter your move (1-9): \").strip())\n",
        "        if self.board[choice - 1] == \" \":\n",
        "            self.board[choice - 1] = self.player\n",
        "        else:\n",
        "            print(\"That space is already taken.\")\n",
        "            self.player_move()\n",
        "\n",
        "    def check_for_winner(self):\n",
        "        winning_combinations = [\n",
        "            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # rows\n",
        "            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # columns\n",
        "            [0, 4, 8], [2, 4, 6]  # diagonals\n",
        "        ]\n",
        "\n",
        "        for combination in winning_combinations:\n",
        "            if self.board[combination[0]] == self.board[combination[1]] == self.board[combination[2]] != \" \":\n",
        "                return self.board[combination[0]]\n",
        "\n",
        "        if \" \" not in self.board:\n",
        "            return \"Tie\"\n",
        "\n",
        "        return None\n",
        "\n",
        "    def minimax(self, player):\n",
        "        result = self.check_for_winner()\n",
        "\n",
        "        if result is not None:\n",
        "            if result == \"X\":\n",
        "                return -1\n",
        "            elif result == \"O\":\n",
        "                return 1\n",
        "            else:\n",
        "                return 0\n",
        "\n",
        "        if player == \"X\":\n",
        "            best = [None, -2]\n",
        "            for i in range(9):\n",
        "                if self.board[i] == \" \":\n",
        "                    self.board[i] = \"X\"\n",
        "                    score = self.minimax(\"O\")\n",
        "                    self.board[i] = \" \"\n",
        "                    if score > best[1]:\n",
        "                        best = [i, score]\n",
        "        else:\n",
        "            best = [None, 2]\n",
        "            for i in range(9):\n",
        "                if self.board[i] == \" \":\n",
        "                    self.board[i] = \"O\"\n",
        "                    score = self.minimax(\"X\")\n",
        "                    self.board[i] = \" \"\n",
        "                    if score < best[1]:\n",
        "                        best = [i, score]\n",
        "\n",
        "        return best[1]\n",
        "\n",
        "    def computer_move(self):\n",
        "        print(\"Computer turn.\")\n",
        "        move = self.minimax(\"O\")\n",
        "        print(move)\n",
        "        if move == 1:\n",
        "            for i in range(9):\n",
        "                if self.board[i] == \" \":\n",
        "                    self.board[i] = \"O\"\n",
        "                    if self.check_for_winner() == \"O\":\n",
        "                        print(\"Computer chooses {}\".format(i + 1))\n",
        "                        return\n",
        "                    self.board[i] = \" \"\n",
        "\n",
        "        elif move == -1:\n",
        "            for i in range(9):\n",
        "                if self.board[i] == \" \":\n",
        "                    self.board[i] = \"X\"\n",
        "                    if self.check_for_winner() == \"X\":\n",
        "                        self.board[i] = \"O\"\n",
        "                        print(\"Computer chooses {}\".format(i + 1))\n",
        "                        return\n",
        "                    self.board[i] = \" \"\n",
        "\n",
        "        for i in range(9):\n",
        "            if self.board[i] == \" \":\n",
        "                self.board[i] = \"O\"\n",
        "                print(\"Computer chooses {}\".format(i + 1))\n",
        "                break\n",
        "\n",
        "game = TicTacToe()\n",
        "while True:\n",
        "    game.display_board()\n",
        "    game.player_move()\n",
        "    result = game.check_for_winner()\n",
        "    if result is not None:\n",
        "        game.display_board()\n",
        "        if result == \"Tie\":\n",
        "            print(\"Tie game.\")\n",
        "        else:\n",
        "            print(\"{} wins!\".format(result))\n",
        "        break\n",
        "    game.computer_move()\n",
        "    result = game.check_for_winner()\n",
        "    if result is not None:\n",
        "        game.display_board()\n",
        "        if result == \"Tie\":\n",
        "            print(\"Tie game.\")\n",
        "        else:\n",
        "            print(\"{} wins!\".format(result))\n",
        "        break\n"
      ],
      "metadata": {
        "id": "8f5WMuAn4t5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MinMax"
      ],
      "metadata": {
        "id": "MMVdywQg0qyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns optimal value for current player\n",
        "# (Initially called for root and maximizer)\n",
        "def minimax(depth, nodeIndex, maximizingPlayer, values):\n",
        "    # Terminating condition. i.e\n",
        "    # leaf node is reached\n",
        "    if depth == 3:\n",
        "        return values[nodeIndex]\n",
        "\n",
        "    if maximizingPlayer:\n",
        "        best = -float('inf')\n",
        "\n",
        "        # Recur for left and right children\n",
        "        for i in range(0, 2):\n",
        "            val = minimax(depth + 1, nodeIndex * 2 + i,\n",
        "                          False, values)\n",
        "            best = max(best, val)\n",
        "\n",
        "        return best\n",
        "    else:\n",
        "        best = float('inf')\n",
        "\n",
        "        # Recur for left and\n",
        "        # right children\n",
        "        for i in range(0, 2):\n",
        "            val = minimax(depth + 1, nodeIndex * 2 + i,\n",
        "                          True, values)\n",
        "            best = min(best, val)\n",
        "\n",
        "        return best\n",
        "\n",
        "# Driver Code\n",
        "if __name__ == \"__main__\":\n",
        "    values = [2, 4, 6, 8, 1, 2, 10, 12]\n",
        "    print(\"The optimal value is:\", minimax(0, 0, True, values))\n"
      ],
      "metadata": {
        "id": "aa_uJU1L33L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Alpha Beta Pruning"
      ],
      "metadata": {
        "id": "itFU4bot0sAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial values of Alpha and Beta\n",
        "MAX, MIN = 1000, -1000\n",
        "\n",
        "# Returns optimal value for current player\n",
        "# (Initially called for root and maximizer)\n",
        "def minimax(depth, nodeIndex, maximizingPlayer,\n",
        "            values, alpha, beta):\n",
        "    # Terminating condition. i.e\n",
        "    # leaf node is reached\n",
        "    if depth == 3:\n",
        "        return values[nodeIndex]\n",
        "\n",
        "    if maximizingPlayer:\n",
        "        best = MIN\n",
        "\n",
        "        # Recur for left and right children\n",
        "        for i in range(0, 2):\n",
        "            val = minimax(depth + 1, nodeIndex * 2 + i,\n",
        "                          False, values, alpha, beta)\n",
        "            best = max(best, val)\n",
        "            alpha = max(alpha, best)\n",
        "\n",
        "            # Alpha Beta Pruning\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "\n",
        "        return best\n",
        "    else:\n",
        "        best = MAX\n",
        "\n",
        "        # Recur for left and\n",
        "        # right children\n",
        "        for i in range(0, 2):\n",
        "            val = minimax(depth + 1, nodeIndex * 2 + i,\n",
        "                          True, values, alpha, beta)\n",
        "            best = min(best, val)\n",
        "            beta = min(beta, best)\n",
        "\n",
        "            # Alpha Beta Pruning\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "\n",
        "        return best\n",
        "\n",
        "# Driver Code\n",
        "if __name__ == \"__main__\":\n",
        "    values = [2, 4, 6, 8, 1, 2, 10, 12]\n",
        "    print(\"The optimal value is:\", minimax(0, 0, True, values, MIN, MAX))"
      ],
      "metadata": {
        "id": "Z4v1ywVc3uc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regression"
      ],
      "metadata": {
        "id": "_YIch0d2w770"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "data = pd.read_csv('data.csv')\n",
        "X = data[['x1', 'x2', ... , 'xn']] # independent variables\n",
        "y = data['y'] # dependent variable\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "predictions = model.predict(new_data)\n",
        "\n",
        "#Least Squares\n",
        "slope, intercept = np.polyfit(x, y, 1)"
      ],
      "metadata": {
        "id": "PawxbEFI4ZVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metrics"
      ],
      "metadata": {
        "id": "J4QqvyVZCMF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#R2 score\n",
        "r2 = r2_score(y_actual, y_pred)\n",
        "print('R-squared score:', r2)\n",
        "\n",
        "#MSE & RSE  \n",
        "rmse = np.sqrt(mean_squared_error(y_actual, y_pred))\n",
        "rse = np.sqrt(sum((y_pred - y_actual)**2) / (len(y_actual) - 2))\n",
        "print('RMSE:', rmse)\n",
        "print('RSE:', rse)\n",
        "\n",
        "#accuracy_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
        "acc = accuracy_score(y_test, preds)\n",
        "print('Accuracy:', acc)\n",
        "\n",
        "#ROC\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
        "probs = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate false positive rate, true positive rate, and thresholds for ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.plot(fpr, tpr, linestyle='--', label='Logistic Regression')\n",
        "\n",
        "# Add labels and legend to plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "#confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "hE8xgQj1CTme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree"
      ],
      "metadata": {
        "id": "gBEkG7KEClX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "-QS-Oo9JCnEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K means Classifier"
      ],
      "metadata": {
        "id": "VIoHsv4tCo_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create the classifier object\n",
        "clf = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Train the model on the data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the output for the test data\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "EJoz0BfCCqtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM"
      ],
      "metadata": {
        "id": "2NGtO4acC6G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create the classifier object\n",
        "clf = SVC(kernel='linear', C=1.0)\n",
        "\n",
        "\n",
        "# Train the model on the data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the output for the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "svm = SVC(kernel='rbf')\n",
        "\n",
        "# train the SVM classifier\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred = svm.predict(X_test)\n"
      ],
      "metadata": {
        "id": "ZY1VwxoeC8i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KMeans\n"
      ],
      "metadata": {
        "id": "D7zyCWE7C-Se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=2)\n",
        "\n",
        "# fit the K-Means model on the data\n",
        "kmeans.fit(X)\n",
        "\n",
        "# get the coordinates of the centroids\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# get the labels of each point\n",
        "labels = kmeans.labels_\n"
      ],
      "metadata": {
        "id": "PQ5hhQC6DAhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reinforcement Learning"
      ],
      "metadata": {
        "id": "t48ugGbRw_GM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Frozen Lake"
      ],
      "metadata": {
        "id": "KwgC36ytxg2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "#setting environment\n",
        "env = gym.make('FrozenLake-v1')\n",
        "\n",
        "\n",
        "#set hyperparams\n",
        "alpha = 0.1  \n",
        "gamma = 0.99\n",
        "num_episodes = 10000 #doubled the training \n",
        "\n",
        "#initialize Q table\n",
        "num_states = env.observation_space.n\n",
        "num_actions = env.action_space.n\n",
        "\n",
        "\n",
        "Q = np.zeros((env.observation_space.n,env.action_space.n))\n",
        "\n",
        "#run Q learning algorithm now\n",
        "for i in range(num_episodes):\n",
        "    #reset env\n",
        "    state = env.reset()\n",
        "\n",
        "    done = False\n",
        "\n",
        "    total_reward = 0\n",
        "\n",
        "\n",
        "    while not done:\n",
        "        if np.random.uniform(0,1) < 0.5:\n",
        "            action = env.action_space.sample()\n",
        "\n",
        "        else:\n",
        "            action = np.argmax(Q[state,:])\n",
        "\n",
        "        #take action and observe next state and reward\n",
        "\n",
        "        next_state,reward,done,info = env.step(action)\n",
        "\n",
        "        # Update the Q-value of the (state, action) pair\n",
        "\n",
        "        Q[state,action] = Q[state,action] + alpha *(reward + gamma *np.max(Q[next_state,:])-Q[state,action])\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "     \n",
        "    print(f\"Episode {i}: Total reward = {total_reward}\") \n",
        "\n",
        "\n",
        "#tesing\n",
        "num_test_episodes = 500 #increased from 100 to 500\n",
        "num_test_steps = 500 #increased from 100 to 500\n",
        "num_successes = 0\n",
        "\n",
        "\n",
        "for i in range(num_test_episodes):\n",
        "    state=env.reset()\n",
        "    done = False\n",
        "    steps = 0\n",
        "\n",
        "\n",
        "    while not done and steps < num_test_steps:\n",
        "        action = np.argmax(Q[state,:])\n",
        "\n",
        "        next_state,reward,done,info = env.step(action)\n",
        "\n",
        "        state=next_state\n",
        "        steps+=1\n",
        "\n",
        "    if state==15:\n",
        "        num_successes+=1\n",
        "\n",
        "print(\"Success rate:\", num_successes/num_test_episodes) "
      ],
      "metadata": {
        "id": "agPM4ov5BNFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traffic v3"
      ],
      "metadata": {
        "id": "IaIatrpWBHQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('Taxi-v3')\n",
        "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "learning_rate = 0.8\n",
        "discount_factor = 0.95\n",
        "num_episodes = 5000\n",
        "max_steps = 100\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    \n",
        "    for step in range(max_steps):\n",
        "        epsilon = 0.1  \n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample() \n",
        "        else:\n",
        "            action = np.argmax(Q[state, :])\n",
        "\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        Q[state, action] = Q[state, action] + learning_rate * (\n",
        "                reward + discount_factor * np.max(Q[next_state, :]) - Q[state, action])\n",
        "\n",
        "        total_reward += reward\n",
        "        state = next_state\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    print(\"Episode:\", episode, \"Total Reward:\", total_reward)\n",
        "\n",
        "num_eval_episodes = 100\n",
        "eval_rewards = []\n",
        "\n",
        "for episode in range(num_eval_episodes):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = np.argmax(Q[state, :])\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "        state = next_state\n",
        "\n",
        "    eval_rewards.append(total_reward)\n",
        "\n",
        "print(\"Average Evaluation Reward:\", np.mean(eval_rewards))\n"
      ],
      "metadata": {
        "id": "3VS6WwVWBJP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 3 RL"
      ],
      "metadata": {
        "id": "fBFRojK9xjml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_nodes = 5\n",
        "sink_node = 0\n",
        "cost_matrix = np.array([[0, 1, 2, 3, 4],\n",
        "                        [1, 0, 1, 2, 3],\n",
        "                        [2, 1, 0, 1, 2],\n",
        "                        [3, 2, 1, 0, 1],\n",
        "                        [4, 3, 2, 1, 0]])\n",
        "\n",
        "Q = np.zeros((num_nodes, num_nodes))\n",
        "\n",
        "learning_rate = 0.8\n",
        "discount_factor = 0.95\n",
        "num_episodes = 2000\n",
        "max_steps = 100\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    state = np.random.randint(0, num_nodes)  \n",
        "    total_cost = 0\n",
        "    done = False\n",
        "    \n",
        "    for step in range(max_steps):\n",
        "        epsilon = 0.1 \n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = np.random.randint(0, num_nodes)  \n",
        "        else:\n",
        "            action = np.argmax(Q[state, :])  \n",
        "\n",
        "        cost = cost_matrix[state, action]\n",
        "\n",
        "        Q[state, action] = Q[state, action] + learning_rate * (\n",
        "                cost + discount_factor * np.min(Q[action, :]) - Q[state, action])\n",
        "\n",
        "        total_cost += cost\n",
        "        state = action\n",
        "\n",
        "        if state == sink_node:\n",
        "            break\n",
        "\n",
        "    print(\"Episode:\", episode, \"Total Cost:\", total_cost)\n",
        "\n",
        "num_eval_episodes = 10\n",
        "eval_costs = []\n",
        "\n",
        "for episode in range(num_eval_episodes):\n",
        "    state = np.random.randint(0, num_nodes) \n",
        "    total_cost = 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = np.argmax(Q[state, :])\n",
        "        cost = cost_matrix[state, action]\n",
        "        total_cost += cost\n",
        "        state = action\n",
        "\n",
        "        if state == sink_node:\n",
        "            break\n",
        "\n",
        "    eval_costs.append(total_cost)\n",
        "\n",
        "print(\"Average Evaluation Cost:\", np.mean(eval_costs))\n"
      ],
      "metadata": {
        "id": "cNRbigRtzwYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Epsilon Greedy"
      ],
      "metadata": {
        "id": "Rbkk9txRBjx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#another way for Q-learning \n",
        "\n",
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "# Create the FrozenLake-v0 environment\n",
        "env = gym.make('FrozenLake-v1')\n",
        "\n",
        "# Set the hyperparameters\n",
        "num_episodes = 10000\n",
        "max_steps = 100\n",
        "alpha = 0.1\n",
        "gamma = 0.99\n",
        "epsilon = 1.0\n",
        "epsilon_min = 0.01\n",
        "epsilon_decay = 0.99\n",
        "\n",
        "# Initialize the Q-table\n",
        "num_states = env.observation_space.n\n",
        "num_actions = env.action_space.n\n",
        "Q = np.zeros((num_states, num_actions))\n",
        "\n",
        "# Define the epsilon-greedy policy\n",
        "def epsilon_greedy_policy(state, epsilon):\n",
        "    if np.random.rand() < epsilon:\n",
        "        # Take a random action\n",
        "        action = env.action_space.sample()\n",
        "    else:\n",
        "        # Choose the best action from the Q-table\n",
        "        action = np.argmax(Q[state, :])\n",
        "    return action\n",
        "\n",
        "# Loop over episodes\n",
        "for episode in range(num_episodes):\n",
        "    # Reset the environment and get the initial state\n",
        "    state = env.reset()\n",
        "    \n",
        "    # Choose the initial action using the epsilon-greedy policy\n",
        "    action = epsilon_greedy_policy(state, epsilon)\n",
        "    \n",
        "    # Initialize the total reward for the episode\n",
        "    total_reward = 0\n",
        "    \n",
        "    # Loop over steps within this episode\n",
        "    for t in range(max_steps):\n",
        "        # Take the chosen action and observe the next state and reward\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        \n",
        "        # Choose the next action using the epsilon-greedy policy\n",
        "        next_action = epsilon_greedy_policy(next_state, epsilon)\n",
        "        \n",
        "        # Update the Q-table\n",
        "        td_error = reward + gamma * Q[next_state, next_action] - Q[state, action]\n",
        "        Q[state, action] += alpha * td_error\n",
        "        \n",
        "        # Update the state, action, and total reward\n",
        "        state = next_state\n",
        "        action = next_action\n",
        "        total_reward += reward\n",
        "        \n",
        "        # If the episode is complete, break out of the loop\n",
        "        if done:\n",
        "            break\n",
        "    \n",
        "    # Decay the epsilon value for the next episode\n",
        "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
        "    \n",
        "    # Print the total reward for this episode\n",
        "    print(f\"Episode {episode}: Total reward = {total_reward}\")\n",
        "    \n",
        "# Print the final Q-table\n",
        "print(\"Final Q-table:\")\n",
        "print(Q)\n"
      ],
      "metadata": {
        "id": "AO_WGj00BmOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SARSA"
      ],
      "metadata": {
        "id": "axIs-DnpBoJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "# FrozenLake-v0 gym environment\n",
        "env = gym.make('FrozenLake-v1')\n",
        "\n",
        "# Parameters\n",
        "epsilon = 0.9\n",
        "total_episodes = 10000\n",
        "max_steps = 100\n",
        "alpha = 0.05\n",
        "gamma = 0.95\n",
        "  \n",
        "#Initializing the Q-vaue\n",
        "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "\n",
        "# Function to choose the next action with episolon greedy\n",
        "def choose_action(state):\n",
        "    action=0\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        action = env.action_space.sample()\n",
        "    else:\n",
        "        action = np.argmax(Q[state, :])\n",
        "    return action\n",
        "    \n",
        "#Initializing the reward\n",
        "reward=0\n",
        "  \n",
        "# Starting the SARSA learning\n",
        "for episode in range(total_episodes):\n",
        "    t = 0\n",
        "    state1 = env.reset()\n",
        "    action1 = choose_action(state1)\n",
        "  \n",
        "    while t < max_steps:\n",
        "        # Visualizing the training\n",
        "#         env.render()\n",
        "          \n",
        "        # Getting the next state\n",
        "        state2, reward, done, info = env.step(action1)\n",
        "  \n",
        "        #Choosing the next action\n",
        "        action2 = choose_action(state2)\n",
        "          \n",
        "        #Learning the Q-value\n",
        "        Q[state1, action1] = Q[state1, action1] + alpha * (reward + gamma * Q[state2, action2] - Q[state1, action1])\n",
        "  \n",
        "        state1 = state2\n",
        "        action1 = action2\n",
        "          \n",
        "        #Updating the respective vaLues\n",
        "        t += 1\n",
        "        reward += 1\n",
        "          \n",
        "        #If at the end of learning process\n",
        "        if done:\n",
        "            break\n",
        "            \n",
        "#Evaluating the performance\n",
        "print (\"Performace : \", reward/total_episodes)\n",
        "  \n",
        "#Visualizing the Q-matrix\n",
        "print(Q)"
      ],
      "metadata": {
        "id": "eJqJJowTBpVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cart Pole"
      ],
      "metadata": {
        "id": "g8jX3Tw7B4UJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3\n",
        "!pip install pyglet\n",
        "############################\n",
        "import gym \n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "###########################\n",
        "\n",
        "environment_name = \"CartPole-v0\"\n",
        "env = gym.make(environment_name)\n",
        "episodes = 5\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0 \n",
        "    \n",
        "    while not done:\n",
        "        #env.render()\n",
        "        action = env.action_space.sample()\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "    print('Episode:{} Score:{}'.format(episode, score))\n",
        "env.close()\n",
        "\n",
        "#########################\n",
        "env = gym.make(environment_name)\n",
        "env = DummyVecEnv([lambda: env])\n",
        "model = PPO('MlpPolicy', env, verbose = 1)\n",
        "model.learn(total_timesteps=20000)\n",
        "\n",
        "\n",
        "##########################\n",
        "\n",
        "obs = env.reset()\n",
        "while True:\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, done, info = env.step(action)\n",
        "    #env.render()\n",
        "    if done: \n",
        "        print('info', info)\n",
        "        break\n",
        "env.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "58BkrRZcB5jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayes Net"
      ],
      "metadata": {
        "id": "OsoTHDT2mXWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "\n",
        "# Define the Bayesian network structure\n",
        "model = BayesianModel([('guest', 'prize'), ('choice', 'prize'), ('choice', 'guest')])\n",
        "\n",
        "# Define the conditional probability tables (CPDs) for each node\n",
        "guest_cpd = TabularCPD(variable='guest', variable_card=3, values=[[1/3, 1/3, 1/3]])\n",
        "choice_cpd = TabularCPD(variable='choice', variable_card=3, values=[[1/3, 1/3, 1/3]])\n",
        "prize_cpd = TabularCPD(variable='prize', variable_card=3,\n",
        "                       evidence=['guest', 'choice'], evidence_card=[3, 3],\n",
        "                       values=[[0, 0, 0, 0, 0.5, 1, 0, 1, 0.5],\n",
        "                               [0.5, 0, 0.5, 1, 0, 0, 0.5, 0, 0.5],\n",
        "                               [0.5, 1, 0.5, 0, 0.5, 0, 0.5, 0, 0]])\n",
        "\n",
        "# Add the CPDs to the model\n",
        "model.add_cpds(guest_cpd, choice_cpd, prize_cpd)\n",
        "\n",
        "# Check if the model is valid\n",
        "model.check_model()\n",
        "\n",
        "# Calculate the probabilities for winning the prize\n",
        "result = model.query(variables=['prize'], evidence={'choice': 1, 'guest': 2})\n",
        "print(result['prize'])"
      ],
      "metadata": {
        "id": "_Av2C47jmZQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from pomegranate import *\n",
        "\n",
        "study_time = DiscreteDistribution({'1hour': 0.5, '2hour': 0.4, '3hour': 0.1})\n",
        "\n",
        "iq = DiscreteDistribution({'100 iq': 0.2, '110 iq': 0.6, '120 iq': 0.2, })\n",
        "\n",
        "# Define the conditional probability table\n",
        "exam_score = ConditionalProbabilityTable(\n",
        "    [        # Study Time: 1 hour        # IQ: 100        \n",
        "        ['1hour', '100 iq', 'Poor', 0.2],\n",
        "        ['1hour', '100 iq', 'Average', 0.5],\n",
        "        ['1hour', '100 iq', 'Excellent', 0.3],\n",
        "        ['1hour', '110 iq', 'Poor', 0.15],\n",
        "        ['1hour', '110 iq', 'Average', 0.6],\n",
        "        ['1hour', '110 iq', 'Excellent', 0.25],\n",
        "        ['1hour', '120 iq', 'Poor', 0.1],\n",
        "        ['1hour', '120 iq', 'Average', 0.5],\n",
        "        ['1hour', '120 iq', 'Excellent', 0.4],\n",
        "        # Study Time: 2 hours\n",
        "        # IQ: 100\n",
        "        ['2hour', '100 iq', 'Poor', 0.1],\n",
        "        ['2hour', '100 iq', 'Average', 0.4],\n",
        "        ['2hour', '100 iq', 'Excellent', 0.5],\n",
        "        ['2hour', '110 iq', 'Poor', 0.05],\n",
        "        ['2hour', '110 iq', 'Average', 0.5],\n",
        "        ['2hour', '110 iq', 'Excellent', 0.45],\n",
        "        ['2hour', '120 iq', 'Poor', 0.02],\n",
        "        ['2hour', '120 iq', 'Average', 0.3],\n",
        "        ['2hour', '120 iq', 'Excellent', 0.68],\n",
        "        # Study Time: 3 hours\n",
        "        # IQ: 100\n",
        "        ['3hour', '100 iq', 'Poor', 0.05],\n",
        "        ['3hour', '100 iq', 'Average', 0.3],\n",
        "        ['3hour', '100 iq', 'Excellent', 0.65],\n",
        "        ['3hour', '110 iq', 'Poor', 0.02],\n",
        "        ['3hour', '110 iq', 'Average', 0.4],\n",
        "        ['3hour', '110 iq', 'Excellent', 0.58],\n",
        "        ['3hour', '120 iq', 'Poor', 0.01],\n",
        "        ['3hour', '120 iq', 'Average', 0.25],\n",
        "        ['3hour', '120 iq', 'Excellent', 0.74]\n",
        "    ], \n",
        "    [study_time, iq]\n",
        ")\n",
        "\n",
        "\n",
        "pass_exam = ConditionalProbabilityTable(\n",
        "    [[ 'Poor', False, 1],\n",
        "     [ 'Poor', True, 0],\n",
        "     [ 'Average', False, 0.5],\n",
        "     [ 'Average', True, 0.5],\n",
        "     [ 'Excellent', True, 1],\n",
        "     [ 'Excellent', False, 0],\n",
        "     ],\n",
        "    [exam_score])\n",
        "\n",
        "d1 = State(study_time, name='study_time')\n",
        "d2 = State(iq, name='iq')\n",
        "d3 = State(exam_score, name='exam_score')\n",
        "d4 = State(pass_exam, name='pass_exam')\n",
        "\n",
        "network = BayesianNetwork()\n",
        "network.add_states(d1,d2,d3,d4)\n",
        "network.add_edge(d1,d3)\n",
        "network.add_edge(d2,d3)\n",
        "network.add_edge(d3,d4)\n",
        "\n",
        "network.bake()\n",
        "beliefs = network.predict_proba({'study_time': '1hour', 'iq':'100 iq'})\n",
        "print(\"n\".join( \"{}t{}\".format( state.name, str(belief) ) for state, belief in zip( network.states, beliefs )))"
      ],
      "metadata": {
        "id": "H_xKOTG4mafY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age = DiscreteDistribution({'<40': 1./3, '40-60': 1./3, '>60': 1./3})\n",
        "cholestrol = DiscreteDistribution({'100-150': 1./3, '150-250': 1./3, '250-255': 1./3 })\n",
        "\n",
        "heart_disease = ConditionalProbabilityTable(\n",
        "    [        ['<40', '100-150', 'No', 0.75],\n",
        "        ['<40', '100-150', 'Yes', 0.25],\n",
        "        ['<40', '150-250', 'No', 0.4],\n",
        "        ['<40', '150-250', 'Yes', 0.6],\n",
        "        ['<40', '250-255', 'No', 0.2],\n",
        "        ['<40', '250-255', 'Yes', 0.8],\n",
        "        ['40-60', '100-150', 'No', 0.37],\n",
        "        ['40-60', '100-150', 'Yes', 0.63],\n",
        "        ['40-60', '150-250', 'No', 0.37],\n",
        "        ['40-60', '150-250', 'Yes', 0.63],\n",
        "        ['40-60', '250-255', 'No', 0.12],\n",
        "        ['40-60', '250-255', 'Yes', 0.88],\n",
        "        ['>60', '100-150', 'No', 0.375],\n",
        "        ['>60', '100-150', 'Yes', 0.625],\n",
        "        ['>60', '150-250', 'No', 0.5],\n",
        "        ['>60', '150-250', 'Yes', 0.5],\n",
        "        ['>60', '250-255', 'No', 0.375],\n",
        "        ['>60', '250-255', 'Yes', 0.625],\n",
        "    ], \n",
        "    [age, cholestrol]\n",
        ")\n",
        "d1 = State(age, name='age')\n",
        "d2 = State(cholestrol, name='cholestrol')\n",
        "d3 = State(heart_disease, name='heart_disease')\n",
        "\n",
        "network = BayesianNetwork()\n",
        "network.add_states(d1,d2,d3)\n",
        "network.add_edge(d1,d3)\n",
        "network.add_edge(d2,d3)\n",
        "network.bake()\n",
        "beliefs = network.predict_proba({'age': '40-60', 'cholestrol':'100-150'})\n",
        "print(\"n\".join( \"{}t{}\".format( state.name, str(belief) ) for state, belief in zip( network.states, beliefs )))"
      ],
      "metadata": {
        "id": "9GEc1l9KmeFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pomegranate import *\n",
        "\n",
        "#dist for parent nodes\n",
        "cpu = DiscreteDistribution({\"Low\": 0.1, \"Medium\": 0.2, \"High\": 0.5})\n",
        "memory = DiscreteDistribution({\"Low\": 0.1, \"Medium\": 0.2, \"High\": 0.5})\n",
        "disk = DiscreteDistribution({\"Low\": 0.1, \"Medium\": 0.2, \"High\": 0.5})\n",
        "network = DiscreteDistribution({\"Low\": 0.1, \"Medium\": 0.2, \"High\": 0.5})\n",
        "OS = DiscreteDistribution({\"Windows\": 0.5, \"Linux\": 0.5})\n",
        "\n",
        "#CPT for app probabilities\n",
        "\n",
        "lcpu = [\"Low\",\"Medium\",\"High\"]\n",
        "lmemory = [\"Low\",\"Medium\",\"High\"]\n",
        "ldisk = [\"Low\",\"Medium\",\"High\"]\n",
        "lnetwork = [\"Low\",\"Medium\",\"High\"]\n",
        "lOS = [\"Windows\",\"Linux\"]\n",
        "lapp = [\"Desktop\",\"Mobile\"]\n",
        "count=0\n",
        "table=list()\n",
        "for i in lcpu:\n",
        "    for j in lmemory:\n",
        "        for k in ldisk:\n",
        "            for l in lnetwork:\n",
        "                for m in lOS:\n",
        "                    for n in lapp:\n",
        "                        #print(i,j,k,l,m,n,\"0.0\")\n",
        "                        rec=[i,j,k,l,m,n,0.5]\n",
        "                        table.append(rec)\n",
        "                        count+=1\n",
        "\n",
        "app = ConditionalProbabilityTable(table,[cpu,memory,disk,network,OS])\n",
        "\n",
        "failure = ConditionalProbabilityTable(\n",
        "    [[\"Desktop\",\"pass\",0.6],\n",
        "     [\"Desktop\",\"fail\",0.4],\n",
        "     [\"Mobile\",\"pass\",0.7],\n",
        "     [\"Mobile\",\"fail\",0.3]],\n",
        "    [app])\n",
        "\n",
        "# Create the Bayesian Network object and add the nodes to the network\n",
        "model = BayesianNetwork(\"Failure Predictorr\")\n",
        "\n",
        "#Creating the nodes for the events\n",
        "nfailure = Node(failure, name=\"failure\")\n",
        "napp = Node(app, name=\"app\")\n",
        "ndisk = Node(disk, name=\"disk\")\n",
        "nnetwork = Node(network, name=\"network\")\n",
        "nmemory = Node(memory, name=\"memory\")\n",
        "nOS = Node(OS, name=\"OS\")\n",
        "ncpu = Node(cpu, name=\"cpu\")\n",
        "\n",
        "model.add_states(nfailure,napp,ncpu,nmemory,ndisk,nnetwork,nOS)\n",
        "\n",
        "# Add edges between the nodes to represent the dependencies between them\n",
        "model.add_edge(ncpu,napp)\n",
        "model.add_edge( nmemory,napp)\n",
        "model.add_edge( ndisk,napp)\n",
        "model.add_edge( nOS,napp)\n",
        "model.add_edge( nnetwork,napp)\n",
        "model.add_edge( napp,nfailure)\n",
        "\n",
        "\n",
        "# Finalize the network structure and start the model\n",
        "model.bake()\n",
        "\n",
        "# Probability of sample events leading to system failure\n",
        "observations={'cpu': 'High', 'memory': 'Low', 'disk': 'Low', 'network': 'Low', 'OS': 'Windows'}\n",
        "#print(model.predict_proba({\"failure\": \"pass\"}, evidence=observations))\n",
        "print(model.predict_proba({\"failure\": \"pass\", **observations}))"
      ],
      "metadata": {
        "id": "NPDa9AqenxSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1 Linear Regression"
      ],
      "metadata": {
        "id": "Sg_Qvzzh9fsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Read\n",
        "df1 = pd.read_csv(r'C:\\Users\\Mohsin\\Desktop\\Dataset_Q1.csv')\n",
        "df1.head()\n",
        "#Dataframe\n",
        "X = df1[['Size (sq ft)']]\n",
        "y = df1['Price (USD)']\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split the data into training and test sets with a 70/30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#Learning\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)  # make predictions\n",
        "# evaluate the model\n",
        "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
        "mse = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('Mean Absolute error:', mse)\n",
        "print('R2 score:', r2)"
      ],
      "metadata": {
        "id": "RjGCAO3F9i-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2 Decision Tree"
      ],
      "metadata": {
        "id": "JssZhh3mm_-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#File Read\n",
        "df2 = pd.read_csv(r'C:\\Users\\Mohsin\\Desktop\\Dataset_Q2.csv')\n",
        "df2.head()\n",
        "\n",
        "#Encoding\n",
        "categorical_cols = df2.select_dtypes(include=['object'])\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df2[col] = le.fit_transform(df2[col])\n",
        "\n",
        "df2\n",
        "#Dataframe\n",
        "X = df2.drop(columns=['Customer ID','Churn','Phone Service'])\n",
        "y = df2.iloc[:,-1]\n",
        "\n",
        "#Spliting\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3,random_state=42)\n",
        "\n",
        "\n",
        "#Decision Tree Classifier\n",
        "dtc = DecisionTreeClassifier(criterion = 'entropy', max_depth=10, random_state=42)\n",
        "dtc.fit(X_train,y_train)\n",
        "y_pred = dtc.predict(X_test)\n",
        "score = accuracy_score(y_pred, y_test)\n",
        "print(score)"
      ],
      "metadata": {
        "id": "Ya0ueZv89b3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3 KNNeighbours\n"
      ],
      "metadata": {
        "id": "tIshuLVm9kzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.read_csv(r'C:\\Users\\Mohsin\\Desktop\\Dataset_Q3.csv')\n",
        "df3.head()\n",
        "\n",
        "#Dataframe\n",
        "X = df3.iloc[:,1:-1]\n",
        "y = df3.iloc[:,-1]\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Odd Points so take square root of 9 and always take odd points i.e sqrt(144)=12 but take 11\n",
        "knn = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
        "knn.fit(x_train,y_train)\n",
        "y_pred = knn.predict(x_test)\n",
        "\n",
        "\n",
        "score = accuracy_score(y_test, y_pred)\n",
        "mat = confusion_matrix(y_pred, y_test)\n",
        "print('Score:', score)\n",
        "print(mat)\n",
        "\n",
        "#plot\n",
        "sns.scatterplot(data=x_train, x='Sepal Length', y='Petal Width', hue=y_train)\n",
        "sns.scatterplot(data=x_test, x='Sepal Length', y='Petal Width',  hue=y_pred, palette='Reds')"
      ],
      "metadata": {
        "id": "h372Hkib95hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4 SVM"
      ],
      "metadata": {
        "id": "7Y3cF94R9rq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read\n",
        "df4 = pd.read_csv(r'C:\\Users\\Mohsin\\Desktop\\Dataset_Q4.csv')\n",
        "df4.head()\n",
        "\n",
        "#Encode\n",
        "df4.drop(columns='ID',inplace=True)\n",
        "cat_cols = df4.select_dtypes(include=['object'])\n",
        "\n",
        "for col in cat_cols:\n",
        "    enc = LabelEncoder()\n",
        "    df4[col] = enc.fit_transform(df4[col])\n",
        "    \n",
        "print(df4)\n",
        "#plot\n",
        "sns.pairplot(df4,hue='Fraudulent')\n",
        "\n",
        "#Dataframe\n",
        "X = df4.drop(columns=['Fraudulent'])\n",
        "y = df4['Fraudulent']\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC(kernel='linear')\n",
        "svc.fit(X_train, y_train)\n",
        "y_pred = svc.predict(X_test)\n",
        "print(accuracy_score(y_pred, y_test))"
      ],
      "metadata": {
        "id": "XSGlmndc9nqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5 Kmeans"
      ],
      "metadata": {
        "id": "-bkr4ouE99AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read\n",
        "df5 = pd.read_csv(r'C:\\Users\\Mohsin\\Desktop\\Dataset_Q5.csv')\n",
        "df5.head()\n",
        "\n",
        "#Encoding\n",
        "cat_cols = df5.select_dtypes(include=['object'])\n",
        "\n",
        "for col in cat_cols:\n",
        "    enc = LabelEncoder()\n",
        "    df5[col] = enc.fit_transform(df5[col])\n",
        "    \n",
        "#Dataframe    \n",
        "X = df5.drop(columns=[' Items Purchased'])\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "wss = []\n",
        "for i in range(1,6):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++' ,random_state=42)\n",
        "    kmeans.fit_predict(X)\n",
        "    wss.append(kmeans.inertia_)\n",
        "\n",
        "plt.plot(range(1,6),wss)\n",
        "plt.title(\"The Elbow Method\")\n",
        "plt.xlabel(\"Number of clusters\")\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "for i in range(2,7):\n",
        "    kmeans = KMeans(n_clusters=i)\n",
        "    kmeans.fit(X)\n",
        "    score = silhouette_score(X,kmeans.labels_)\n",
        "    print(f\"for cluster {i}: The Score is {score}\")\n",
        "    \n",
        "km = KMeans(n_clusters=6, init='k-means++')\n",
        "y_means = km.fit_predict(X)\n",
        "\n",
        "\n",
        "plt.scatter(X.loc[:,' Age'], X.loc[:,' Total Spending'], c=km.labels_)\n",
        "\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Total Spending')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uFQz157i9_D6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
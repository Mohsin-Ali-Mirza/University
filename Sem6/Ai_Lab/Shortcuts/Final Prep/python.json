{
	"minimaxttt": {
		"prefix": "minimaxttt",
		"body": [
		  "#TIC TAC TOE USING MINIMAX ALGO",
		  "",
		  "def printBoard(board):",
		  "    print(board[1] + '|' + board[2] + '|' + board[3])",
		  "    print('-+-+-')",
		  "    print(board[4] + '|' + board[5] + '|' + board[6])",
		  "    print('-+-+-')",
		  "    print(board[7] + '|' + board[8] + '|' + board[9])",
		  "    print(\"\\n\")",
		  "",
		  "",
		  "def spaceIsFree(position):",
		  "    if board[position] == ' ':",
		  "        return True",
		  "    else:",
		  "        return False",
		  "",
		  "",
		  "def insertLetter(letter, position):",
		  "    if spaceIsFree(position):",
		  "        board[position] = letter",
		  "        printBoard(board)",
		  "        if (checkDraw()):",
		  "            print(\"Draw!\")",
		  "            exit()",
		  "        if checkForWin():",
		  "            if letter == 'X':",
		  "                print(\"Bot wins!\")",
		  "                exit()",
		  "            else:",
		  "                print(\"Player wins!\")",
		  "                exit()",
		  "",
		  "        return",
		  "",
		  "",
		  "    else:",
		  "        print(\"Can't insert there!\")",
		  "        position = int(input(\"Please enter new position:  \"))",
		  "        insertLetter(letter, position)",
		  "        return",
		  "",
		  "",
		  "def checkForWin():",
		  "    if (board[1] == board[2] and board[1] == board[3] and board[1] != ' '):",
		  "        return True",
		  "    elif (board[4] == board[5] and board[4] == board[6] and board[4] != ' '):",
		  "        return True",
		  "    elif (board[7] == board[8] and board[7] == board[9] and board[7] != ' '):",
		  "        return True",
		  "    elif (board[1] == board[4] and board[1] == board[7] and board[1] != ' '):",
		  "        return True",
		  "    elif (board[2] == board[5] and board[2] == board[8] and board[2] != ' '):",
		  "        return True",
		  "    elif (board[3] == board[6] and board[3] == board[9] and board[3] != ' '):",
		  "        return True",
		  "    elif (board[1] == board[5] and board[1] == board[9] and board[1] != ' '):",
		  "        return True",
		  "    elif (board[7] == board[5] and board[7] == board[3] and board[7] != ' '):",
		  "        return True",
		  "    else:",
		  "        return False",
		  "",
		  "",
		  "def checkWhichMarkWon(mark):",
		  "    if board[1] == board[2] and board[1] == board[3] and board[1] == mark:",
		  "        return True",
		  "    elif (board[4] == board[5] and board[4] == board[6] and board[4] == mark):",
		  "        return True",
		  "    elif (board[7] == board[8] and board[7] == board[9] and board[7] == mark):",
		  "        return True",
		  "    elif (board[1] == board[4] and board[1] == board[7] and board[1] == mark):",
		  "        return True",
		  "    elif (board[2] == board[5] and board[2] == board[8] and board[2] == mark):",
		  "        return True",
		  "    elif (board[3] == board[6] and board[3] == board[9] and board[3] == mark):",
		  "        return True",
		  "    elif (board[1] == board[5] and board[1] == board[9] and board[1] == mark):",
		  "        return True",
		  "    elif (board[7] == board[5] and board[7] == board[3] and board[7] == mark):",
		  "        return True",
		  "    else:",
		  "        return False",
		  "",
		  "",
		  "def checkDraw():",
		  "    for key in board.keys():",
		  "        if (board[key] == ' '):",
		  "            return False",
		  "    return True",
		  "",
		  "",
		  "def playerMove():",
		  "    position = int(input(\"Enter the position for 'O':  \"))",
		  "    insertLetter(player, position)",
		  "    return",
		  "",
		  "",
		  "def compMove():",
		  "    bestScore = -800",
		  "    bestMove = 0",
		  "    for key in board.keys():",
		  "        if (board[key] == ' '):",
		  "            board[key] = bot",
		  "            score = minimax(board, 0, False)",
		  "            board[key] = ' '",
		  "            if (score > bestScore):",
		  "                bestScore = score",
		  "                bestMove = key",
		  "",
		  "    insertLetter(bot, bestMove)",
		  "    return",
		  "",
		  "",
		  "def minimax(board, depth, isMaximizing):",
		  "    if (checkWhichMarkWon(bot)):",
		  "        return 1",
		  "    elif (checkWhichMarkWon(player)):",
		  "        return -1",
		  "    elif (checkDraw()):",
		  "        return 0",
		  "",
		  "    if (isMaximizing):",
		  "        bestScore = -800",
		  "        for key in board.keys():",
		  "            if (board[key] == ' '):",
		  "                board[key] = bot",
		  "                score = minimax(board, depth + 1, False)",
		  "                board[key] = ' '",
		  "                if (score > bestScore):",
		  "                    bestScore = score",
		  "        return bestScore",
		  "",
		  "    else:",
		  "        bestScore = 800",
		  "        for key in board.keys():",
		  "            if (board[key] == ' '):",
		  "                board[key] = player",
		  "                score = minimax(board, depth + 1, True)",
		  "                board[key] = ' '",
		  "                if (score < bestScore):",
		  "                    bestScore = score",
		  "        return bestScore",
		  "",
		  "",
		  "board = {1: ' ', 2: ' ', 3: ' ',",
		  "         4: ' ', 5: ' ', 6: ' ',",
		  "         7: ' ', 8: ' ', 9: ' '}",
		  "",
		  "printBoard(board)",
		  "print(\"Computer goes first! Good luck.\")",
		  "print(\"Positions are as follow:\")",
		  "print(\"1, 2, 3 \")",
		  "print(\"4, 5, 6 \")",
		  "print(\"7, 8, 9 \")",
		  "print(\"\\n\")",
		  "player = 'O'",
		  "bot = 'X'",
		  "",
		  "",
		  "global firstComputerMove",
		  "firstComputerMove = True",
		  "",
		  "while not checkForWin():",
		  "    compMove()",
		  "    playerMove()",
		  ""
		],
		"description": "minimaxttt"
	  },

	  "abprune": {
		"prefix": "abprune",
		"body": [
		  "# Python3 program to demonstrate",
		  "# working of Alpha-Beta Pruning",
		  " ",
		  "# Initial values of Alpha and Beta",
		  "MAX, MIN = 1000, -1000",
		  " ",
		  "# Returns optimal value for current player",
		  "#(Initially called for root and maximizer)",
		  "def minimax(depth, nodeIndex, maximizingPlayer,",
		  "            values, alpha, beta):",
		  "  ",
		  "    # Terminating condition. i.e",
		  "    # leaf node is reached",
		  "    if depth == 3:",
		  "        return values[nodeIndex]",
		  " ",
		  "    if maximizingPlayer:",
		  "      ",
		  "        best = MIN",
		  " ",
		  "        # Recur for left and right children",
		  "        for i in range(0, 2):",
		  "             ",
		  "            val = minimax(depth + 1, nodeIndex * 2 + i,",
		  "                          False, values, alpha, beta)",
		  "            best = max(best, val)",
		  "            alpha = max(alpha, best)",
		  " ",
		  "            # Alpha Beta Pruning",
		  "            if beta <= alpha:",
		  "                break",
		  "          ",
		  "        return best",
		  "      ",
		  "    else:",
		  "        best = MAX",
		  " ",
		  "        # Recur for left and",
		  "        # right children",
		  "        for i in range(0, 2):",
		  "          ",
		  "            val = minimax(depth + 1, nodeIndex * 2 + i,",
		  "                            True, values, alpha, beta)",
		  "            best = min(best, val)",
		  "            beta = min(beta, best)",
		  " ",
		  "            # Alpha Beta Pruning",
		  "            if beta <= alpha:",
		  "                break",
		  "          ",
		  "        return best",
		  "      ",
		  "# Driver Code",
		  "if __name__ == \"__main__\":",
		  "  ",
		  "    values = [3, 5, 6, 9, 1, 2, 0, -1] ",
		  "    print(\"The optimal value is :\", minimax(0, 0, True, values, MIN, MAX))",
		  "     "
		],
		"description": "abprune"
	  },

	  "nqueenCSP": {
		"prefix": "nqueenCSP",
		"body": [
		  "import numpy as np",
		  "",
		  "def check_valid(arr,row,col,n):",
		  "  #checking if row has any 1s ------------------",
		  "  for i in range(0,n):",
		  "    if arr[row][i]==1 and i!=col:",
		  "      return False",
		  "  ",
		  "  #checking if col has any 1s -------------------",
		  "  for i in range(0,n):",
		  "    if arr[i][col]==1 and i!=row:",
		  "      return False",
		  "  ",
		  "",
		  "  #need 4 separate for loops here for each diagonal direction",
		  "  #(1) above+backwards",
		  "  x=row-1",
		  "  y=col-1",
		  "",
		  "  while x>=0 and y>=0:",
		  "    #print(x,\" \",y,\" \\n\")",
		  "    if arr[x][y]==1:",
		  "      return False",
		  "    ",
		  "    x-=1",
		  "    y-=1",
		  "",
		  "",
		  "  #(2) below+forwards",
		  "  x=row+1",
		  "  y=col+1",
		  "",
		  "  while x<n and y<n:",
		  "    #print(x,\" \",y,\" \\n\")",
		  "    if arr[x][y]==1:",
		  "      return False",
		  "    ",
		  "    x+=1",
		  "    y+=1",
		  "",
		  "",
		  "  ",
		  "",
		  "  #(3) above+forward",
		  "  x=row-1",
		  "  y=col+1",
		  "",
		  "  while x>=0 and y<n:",
		  "    #print(x,\" \",y,\" \\n\")",
		  "    if arr[x][y]==1:",
		  "      return False",
		  "    ",
		  "    x-=1",
		  "    y+=1",
		  "    ",
		  "",
		  "  #(4) below+backward",
		  "  x=row+1",
		  "  y=col-1",
		  "",
		  "  while x<n and y>=0:",
		  "    #print(x,\" \",y,\" \\n\")",
		  "    if arr[x][y]==1:",
		  "      return False",
		  "    ",
		  "    x+=1",
		  "    y-=1",
		  "",
		  "",
		  "",
		  "  #if it passes all above checks means we can place queen there",
		  "  return True",
		  "",
		  "#-----------------------------------------------------------------------",
		  "",
		  "def print_arr(array):",
		  "  for rows in array:",
		  "    for columns in rows:",
		  "      print(columns,end=\" \")",
		  "    print()",
		  "",
		  "#----------------------------------------------------------------------",
		  "",
		  "# n is the dimensions and x is the starting row",
		  "def NQueen_Solver(arr,n,col):",
		  "  if col>=n:",
		  "    return True",
		  "  ",
		  "  for i in range(0,n):",
		  "    if(check_valid(arr,i,col,n)==True):",
		  "      arr[i][col]=1",
		  "",
		  "      col+=1",
		  "      if NQueen_Solver(arr,n,col)==True:",
		  "        return True",
		  "      ",
		  "      col-=1",
		  "      arr[i][col]=0",
		  "",
		  "  return False",
		  "",
		  "",
		  "",
		  "#main-------------------------------------------------------------------",
		  "n=int(input(\"Enter number of N: \"))",
		  "array=np.zeros((n,n),dtype=int)",
		  "",
		  "#sending array and starting row",
		  "NQueen_Solver(array,n,0)",
		  "print(\"\\nSolution:\")",
		  "print_arr(array)",
		  "",
		  "",
		  "",
		  "",
		  ""
		],
		"description": "nqueenCSP"
	  },

	  "cryptalgo": {
		"prefix": "crypthalgo",
		"body": [
		  "def solve_cryptarithmetic(puzzle):",
		  "    \"\"\"",
		  "    Solve a cryptarithmetic puzzle involving the addition of two words.",
		  "    ",
		  "    Args:",
		  "        puzzle (str): A string containing the puzzle to solve, in the format \"WORD1 + WORD2 = RESULT\".",
		  "        ",
		  "    Returns:",
		  "        A dictionary mapping each letter in the puzzle to its assigned value.",
		  "        If no solution exists, returns None.",
		  "    \"\"\"",
		  "    # Parse the puzzle into its constituent words and result",
		  "    words, result = puzzle.split(\" = \")",
		  "    word1, word2 = words.split(\" + \")",
		  "    ",
		  "    # Generate a list of all unique letters in the puzzle",
		  "    letters = set(word1 + word2 + result)",
		  "    ",
		  "    # Check if there are more than 10 unique letters (i.e. puzzle is unsolvable)",
		  "    if len(letters) > 10:",
		  "        return None",
		  "    ",
		  "    # Generate all possible permutations of the digits 0-9 for the unique letters",
		  "    permutations = itertools.permutations(range(10), len(letters))",
		  "    ",
		  "    # Iterate over each permutation and check if it satisfies the puzzle",
		  "    for perm in permutations:",
		  "        # Assign the values from the permutation to each letter in the puzzle",
		  "        letter_values = dict(zip(letters, perm))",
		  "        ",
		  "        # Check if the assigned values satisfy the addition equation",
		  "        if evaluate_word(word1, letter_values) + evaluate_word(word2, letter_values) == evaluate_word(result, letter_values):",
		  "            return letter_values",
		  "    ",
		  "    # No solution found",
		  "    return None",
		  "",
		  "def evaluate_word(word, letter_values):",
		  "    \"\"\"",
		  "    Evaluate a word in a cryptarithmetic puzzle using the assigned values for its letters.",
		  "    ",
		  "    Args:",
		  "        word (str): The word to evaluate.",
		  "        letter_values (dict): A dictionary mapping each letter in the word to its assigned value.",
		  "        ",
		  "    Returns:",
		  "        The numerical value of the word, obtained by replacing each letter with its assigned value.",
		  "    \"\"\"",
		  "    return sum(letter_values[letter] * 10**i for i, letter in enumerate(reversed(word)))",
		  "",
		  "",
		  "puzzle = \"SEND + MORE = MONEY\"",
		  "solution = solve_cryptarithmetic(puzzle)",
		  "",
		  "if solution is not None:",
		  "    print(\"Solution found:\")",
		  "    print(solution)",
		  "else:",
		  "    print(\"No solution found.\")"
		],
		"description": "cryptalgo"
	  },

	  "pgmpy": {
	"prefix": "pgmpy",
	"body": [
		"# Import libraries",
		"import pgmpy.models",
		"import pgmpy.inference",
		"import numpy as np",
		"# The main entry point for this module",
		"def main():",
		"    # Create a dynamic bayesian network",
		"    model = pgmpy.models.DynamicBayesianNetwork()",
		"    ",
		"    # Add nodes",
		"    model.add_nodes_from(['Weather', 'Umbrella'])",
		"    # Print nodes",
		"    print('--- Nodes ---')",
		"    print(model.nodes())",
		"    ",
		"    # Add edges",
		"    model.add_edges_from([(('Umbrella',0), ('Weather',0)),",
		"                          (('Weather',0), ('Weather',1)),",
		"                          (('Umbrella',0), ('Umbrella',1))])",
		"    ",
		"    # Print edges",
		"    print('--- Edges ---')",
		"    print(model.edges())",
		"    print()",
		"    ",
		"    ",
		"    # Print parents",
		"    print('--- Parents ---')",
		"    print('Umbrella 0: {0}'.format(model.get_parents(('Umbrella', 0))))",
		"    print('Weather 0: {0}'.format(model.get_parents(('Weather', 0))))",
		"    print('Weather 1: {0}'.format(model.get_parents(('Weather', 1))))",
		"    print('Umbrella 1: {0}'.format(model.get_parents(('Umbrella', 1))))",
		"    print()",
		"    ",
		"    ",
		"    # Add probabilities",
		"    weather_cpd = pgmpy.factors.discrete.TabularCPD(('Weather', 0), 2, [[0.1, 0.8], ",
		"                                                                        [0.9, 0.2]], ",
		"                                                       evidence=[('Umbrella', 0)], ",
		"                                                       evidence_card=[2])",
		"    ",
		"    umbrella_cpd = pgmpy.factors.discrete.TabularCPD(('Umbrella', 1), 2, [[0.5, 0.5], ",
		"                                                                          [0.5, 0.5]], ",
		"                                                     evidence=[('Umbrella', 0)], ",
		"                                                     evidence_card=[2])",
		"    ",
		"    transition_cpd = pgmpy.factors.discrete.TabularCPD(('Weather', 1), 2, [[0.25, 0.9, 0.1, 0.25], ",
		"                                                                           [0.75, 0.1, 0.9, 0.75]], ",
		"                                                   evidence=[('Weather', 0), ('Umbrella', 1)], ",
		"                                                   evidence_card=[2, 2])",
		"    ",
		"    # Add conditional probability distributions (cpd:s)",
		"    model.add_cpds(weather_cpd, umbrella_cpd, transition_cpd)",
		"    ",
		"    # This method will automatically re-adjust the cpds and the edges added to the bayesian network.",
		"    model.initialize_initial_state()",
		"    ",
		"    # Check if the model is valid, throw an exception otherwise",
		"    model.check_model()",
		"    ",
		"    # Print probability distributions",
		"    print('Probability distribution, P(Weather(0) | Umbrella(0)')",
		"    print(weather_cpd)",
		"    print()",
		"    print('Probability distribution, P(Umbrella(1) | Umbrella(0)')",
		"    print(umbrella_cpd)",
		"    print()",
		"    print('Probability distribution, P(Weather(1) | Umbrella(1), Weather(0)')",
		"    print(transition_cpd)",
		"    print()",
		"    ",
		"    ",
		"    # Make inference",
		"    map = {0: 'Sunny', 1: 'Rainy' }",
		"    dbn_inf = pgmpy.inference.DBNInference(model)",
		"    result = dbn_inf.forward_inference([('Weather', 1)], {('Umbrella', 1):0, ('Weather', 0):0})",
		"    arr = result[('Weather', 1)].values",
		"    print()",
		"    print('Prediction (Umbrella(1) : Yes, Weather(0): Sunny): {0} ({1} %)'.format(map[np.argmax(arr)], np.max(arr) * 100))",
		"    print()",
		"    result = dbn_inf.forward_inference([('Weather', 1)], {('Umbrella', 1):0, ('Weather', 0):1})",
		"    arr = result[('Weather', 1)].values",
		"    print()",
		"    print('Prediction (Umbrella(1) : Yes, Weather(0): Rainy): {0} ({1} %)'.format(map[np.argmax(arr)], np.max(arr) * 100))",
		"    print()",
		"    result = dbn_inf.forward_inference([('Weather', 1)], {('Umbrella', 1):1, ('Weather', 0):0})",
		"    arr = result[('Weather', 1)].values",
		"    print()",
		"    print('Prediction (Umbrella(1) : No, Weather(0): Sunny): {0} ({1} %)'.format(map[np.argmax(arr)], np.max(arr) * 100))",
		"    print()",
		"    result = dbn_inf.forward_inference([('Weather', 1)], {('Umbrella', 1):1, ('Weather', 0):1})",
		"    arr = result[('Weather', 1)].values",
		"    print()",
		"    print('Prediction (Umbrella(1) : No, Weather(0): Rainy): {0} ({1} %)'.format(map[np.argmax(arr)], np.max(arr) * 100))",
		"    print()",
		"",
		"",
		"",
		"",
		"",
		"# Tell python to run main method",
		"if __name__ == \"__main__\": main()"
	],
	"description": "pgmpy"
	},

	"pyagrum": {
		"prefix": "pyagrum",
		"body": [
		  "# Import libraries",
		  "import pyAgrum as gum",
		  "import pyAgrum.lib.notebook as gnb",
		  "import pyAgrum.lib.dynamicBN as gdyn",
		  "import matplotlib.pyplot as plt",
		  "# The main entry point for this module",
		  "def main():",
		  "    # Create a dynamic bayesian network",
		  "    model = gum.BayesNet()",
		  "    ",
		  "    ",
		  "    # Add umbrella nodes",
		  "    umbrella0 = gum.LabelizedVariable('Umbrella(0)','Umbrella day 0',2)",
		  "    umbrella0.changeLabel(0,'Yes')",
		  "    umbrella0.changeLabel(1,'No')",
		  "    u0 = model.add(umbrella0)",
		  "    umbrella1 = gum.LabelizedVariable('Umbrella(1)','Umbrella day 1',2)",
		  "    umbrella1.changeLabel(0,'Yes')",
		  "    umbrella1.changeLabel(1,'No')",
		  "    u1 = model.add(umbrella1)",
		  "    ",
		  "    ",
		  "    # Add weather nodes",
		  "    weather0 = gum.LabelizedVariable('Weather(0)','Weather day 0',2)",
		  "    weather0.changeLabel(0,'Sunny')",
		  "    weather0.changeLabel(1,'Rainy')",
		  "    w0 = model.add(weather0)",
		  "    weather1 = gum.LabelizedVariable('Weather(1)','Weather day 1',2)",
		  "    weather1.changeLabel(0,'Sunny')",
		  "    weather1.changeLabel(1,'Rainy')",
		  "    w1 = model.add(weather1)",
		  "    ",
		  "    ",
		  "    # Add connections between nodes (tail, head)",
		  "    model.addArc(u0, w0)",
		  "    model.addArc(w0, w1)",
		  "    model.addArc(u1, w1)",
		  "    ",
		  "    ",
		  "    ",
		  "    # Add CPT:s (Conditional probability tables)",
		  "    model.cpt(model.idFromName('Weather(0)'))[{'Umbrella(0)':'Yes'}]=[0.1, 0.8]",
		  "    model.cpt(model.idFromName('Weather(0)'))[{'Umbrella(0)':'No'}]=[0.9, 0.2]",
		  "    model.cpt(model.idFromName('Weather(1)'))[{'Umbrella(1)':'Yes'}]=[[0.25, 0.75], ",
		  "                                                                      [0.1, 0.9]]",
		  "    model.cpt(model.idFromName('Weather(1)'))[{'Umbrella(1)':'No'}]=[[0.9, 0.1], ",
		  "                                                                     [0.75, 0.25]]",
		  "    # Create an inference model",
		  "    ie = gum.LazyPropagation(model)",
		  "    ",
		  "    ",
		  "    # Make inference and print the results",
		  "    print('--- Umbrella(0): No ---')",
		  "    ie.setEvidence({'Umbrella(0)':'No'})",
		  "    ie.makeInference()",
		  "    print(ie.posterior('Weather(0)'))",
		  "    print()",
		  "    print('--- Umbrella(0): Yes ---')",
		  "    ie.setEvidence({'Umbrella(0)':'Yes'})",
		  "    ie.makeInference()",
		  "    print(ie.posterior('Weather(0)'))",
		  "    print()",
		  "    print('--- Weather(0): Sunny, Umbrella(1): Yes ---')",
		  "    ie.setEvidence({'Weather(0)':'Sunny', 'Umbrella(1)':'Yes'})",
		  "    ie.makeInference()",
		  "    #gnb.getPosterior(model, {'Weather(0)':'Sunny', 'Umbrella(1)':'Yes'}, 'Weather(1)')",
		  "    #plt.show()",
		  "    print(ie.posterior('Weather(1)'))",
		  "    print()",
		  "    print('--- Weather(0): Sunny, Umbrella(1): No ---')",
		  "    ie.setEvidence({'Weather(0)':'Sunny', 'Umbrella(1)':'No'})",
		  "    ie.makeInference()",
		  "    print(ie.posterior('Weather(1)'))",
		  "    print()",
		  "    print('--- Weather(0): Rainy, Umbrella(1): Yes ---')",
		  "    ie.setEvidence({'Weather(0)':'Rainy', 'Umbrella(1)':'Yes'})",
		  "    ie.makeInference()",
		  "    print(ie.posterior('Weather(1)'))",
		  "    print()",
		  "    print('--- Weather(0): Rainy, Umbrella(1): No ---')",
		  "    ie.setEvidence({'Weather(0)':'Rainy', 'Umbrella(1)':'No'})",
		  "    ie.makeInference()",
		  "    print(ie.posterior('Weather(1)'))",
		  "    print()",
		  "",
		  "",
		  "",
		  "# Tell python to run main method",
		  "if __name__ == \"__main__\": main()"
		],
		"description": "pyagrum"
	  },

	  "hmm": {
		"prefix": "hmm",
		"body": [
		  "# Import libraries",
		  "import numpy as np",
		  "import pandas as pd",
		  "import pprint",
		  "",
		  "",
		  "# Get markov edges",
		  "def get_markov_edges(df):",
		  "    # Create a dictionary",
		  "    edges = {}",
		  "    # Loop columns",
		  "    for column in df.columns:",
		  "        # Loop rows",
		  "        for row in df.index:",
		  "            edges[(row,column)] = df.loc[row,column]",
		  "    # Return edges",
		  "    return edges",
		  "# Viterbi algorithm for shortest path",
		  "# https://github.com/alexsosn/MarslandMLAlgo/blob/master/Ch16/HMM.py",
		  "",
		  "",
		  "def viterbi(pi, a, b, obs):",
		  "    ",
		  "    nStates = np.shape(b)[0]",
		  "    T = np.shape(obs)[0]",
		  "    ",
		  "    path = np.zeros(T)",
		  "    delta = np.zeros((nStates, T))",
		  "    phi = np.zeros((nStates, T))",
		  "    ",
		  "    delta[:, 0] = pi * b[:, obs[0]]",
		  "    phi[:, 0] = 0",
		  "    for t in range(1, T):",
		  "        for s in range(nStates):",
		  "            delta[s, t] = np.max(delta[:, t-1] * a[:, s]) * b[s, obs[t]] ",
		  "            phi[s, t] = np.argmax(delta[:, t-1] * a[:, s])",
		  "    ",
		  "    path[T-1] = np.argmax(delta[:, T-1])",
		  "    for t in range(T-2, -1, -1):",
		  "        path[t] = phi[int(path[t+1]),int(t+1)]",
		  "        ",
		  "    return path, delta, phi",
		  "",
		  "",
		  "# The main entry point for this module",
		  "def main():",
		  "    # Observation states",
		  "    # The director can have an umbrella or not have an umbrella (equally likely)",
		  "    observation_states = ['Umbrella', 'No umbrella']",
		  "   ",
		  "    # Create hidden states with probabilities (250 rainy days per year)",
		  "    p = [0.32, 0.68]",
		  "    #p = [0.5, 0.5]",
		  "    #p = [0.7, 0.3]",
		  "    hidden_states = ['Sunny', 'Rainy']",
		  "    state_space = pd.Series(p, index=hidden_states, name='states')",
		  "    ",
		  "    # Print hidden states",
		  "    print('--- Hidden states ---')",
		  "    print(state_space)",
		  "    print()",
		  "    # Create a hidden states transition matrix with probabilities",
		  "    hidden_df = pd.DataFrame(columns=hidden_states, index=hidden_states)",
		  "    hidden_df.loc[hidden_states[0]] = [0.75, 0.25]",
		  "    hidden_df.loc[hidden_states[1]] = [0.25, 0.75]",
		  "    ",
		  "    ",
		  "    # Print transition matrix",
		  "    print('--- Transition matrix for hidden states ---')",
		  "    print(hidden_df)",
		  "    print()",
		  "    print(hidden_df.sum(axis=1))",
		  "    print()",
		  "    ",
		  "    ",
		  "    # Create matrix of observations with sensor probabilities",
		  "    observations_df = pd.DataFrame(columns=observation_states, index=hidden_states)",
		  "    observations_df.loc[hidden_states[0]] = [0.1, 0.9]",
		  "    observations_df.loc[hidden_states[1]] = [0.8, 0.2]",
		  "    ",
		  "    ",
		  "    # Print observation matrix",
		  "    print('--- Sensor matrix ---')",
		  "    print(observations_df)",
		  "    print()",
		  "    print(observations_df.sum(axis=1))",
		  "    print()",
		  "    ",
		  "    ",
		  "    # Create graph edges and weights",
		  "    hidden_edges = get_markov_edges(hidden_df)",
		  "    observation_edges = get_markov_edges(observations_df)",
		  "    ",
		  "    ",
		  "    # Print edges",
		  "    print('--- Hidden edges ---')",
		  "    pprint.pprint(hidden_edges)",
		  "    print()",
		  "    print('--- Sensor edges ---')",
		  "    pprint.pprint(observation_edges)",
		  "    print()",
		  "    ",
		  "    ",
		  "    # Observations",
		  "    observations_map = {0:'Umbrella', 1:'No umbrella'}",
		  "    observations = np.array([1,1,1,0,1,1,1,0,0,0])",
		  "    observerations_path = [observations_map[v] for v in list(observations)]",
		  "    ",
		  "    ",
		  "    # Get predictions with the viterbi algorithm",
		  "    path, delta, phi = viterbi(p, hidden_df.values, observations_df.values, observations)",
		  "    state_map = {0:'Sunny', 1:'Rainy'}",
		  "    state_path = [state_map[v] for v in path]",
		  "    state_delta = np.amax(delta, axis=0)",
		  "    ",
		  "    ",
		  "    # Print predictions",
		  "    print('--- Predictions ---')",
		  "    print(pd.DataFrame().assign(Observation=observerations_path).assign(Prediction=state_path).assign(Delta=state_delta))",
		  "    print()",
		  "",
		  "",
		  "# Tell python to run main method",
		  "if __name__ == \"__main__\": main()"
		],
		"description": "hmm"
	  },

	  "LinearRegression": {
		"prefix": "LinearRegression",
		"body": [
		  "import pandas as pd",
		  "from sklearn.model_selection import train_test_split",
		  "from sklearn.linear_model import LinearRegression",
		  "from sklearn.metrics import r2_score",
		  "import matplotlib.pyplot as plt",
		  "%matplotlib inline",
		  "################################################",
		  "data = pd.read_csv('data.csv')",
		  "data['Gender'].replace('Female', 0,inplace=True)",
		  "data['Gender'].replace('Male',1,inplace=True)",
		  "data.head()",
		  "###############################################",
		  "fig, ax = plt.subplots()",
		  "ax.scatter(x=data['Height'], y=data['Weight'])",
		  "###################################################",
		  "data.corr()",
		  "###################################################",
		  "data.isnull().sum()",
		  "################################################",
		  "X = data.iloc[:,:-1]",
		  "y = data.iloc[:,-1]",
		  "len(y)",
		  "##############################################",
		  "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=.15)",
		  "lin = LinearRegression()",
		  "lin.fit(X_train, y_train)",
		  "#####################################################",
		  "y_pred = lin.predict(X_test)",
		  "r2_score(y_test, y_pred)",
		  "########################################################",
		  "lin.coef_",
		  "#######################################################",
		  "fig, ax = plt.subplots()",
		  "ax.scatter(x=X['Weight'], y=X['Weight'], c=X['Height'])"
		],
		"description": "LinearRegression"
	  },


	  "DT": {
		"prefix": "DT",
		"body": [
		  "import pandas as pd",
		  "import numpy as np",
		  "",
		  "data = pd.read_csv(\"data.csv\")",
		  "data.head()",
		  "##################33",
		  "data['obese'] = (data.Index >= 4).astype('int')",
		  "data.drop('Index', axis = 1, inplace = True)",
		  "#######################",
		  "print (",
		  "    \"Misclassified when cutting at 100kg:\",",
		  "  data.loc[(data['Weight']>=100) & (data['obese']==0),:].shape[0], \"\\n\",",
		  "  \"Misclassified when cutting at 80kg:\",",
		  "  data.loc[(data['Weight']>=80) & (data['obese']==0),:].shape[0]",
		  ")",
		  "#####################",
		  "def gini_impurity(y):",
		  "  '''",
		  "  Given a Pandas Series, it calculates the Gini Impurity. ",
		  "  y: variable with which calculate Gini Impurity.",
		  "  '''",
		  "  if isinstance(y, pd.Series):",
		  "    p = y.value_counts()/y.shape[0]",
		  "    gini = 1-np.sum(p**2)",
		  "    return(gini)",
		  "",
		  "  else:",
		  "    raise('Object must be a Pandas Series.')",
		  "",
		  "gini_impurity(data.Gender) ",
		  "################################",
		  "def entropy(y):",
		  "  '''",
		  "  Given a Pandas Series, it calculates the entropy. ",
		  "  y: variable with which calculate entropy.",
		  "  '''",
		  "  if isinstance(y, pd.Series):",
		  "    a = y.value_counts()/y.shape[0]",
		  "    entropy = np.sum(-a*np.log2(a+1e-9))",
		  "    return(entropy)",
		  "",
		  "  else:",
		  "    raise('Object must be a Pandas Series.')",
		  "",
		  "entropy(data.Gender)",
		  "#################################",
		  "def variance(y):",
		  "  '''",
		  "  Function to help calculate the variance avoiding nan.",
		  "  y: variable to calculate variance to. It should be a Pandas Series.",
		  "  '''",
		  "  if(len(y) == 1):",
		  "    return 0",
		  "  else:",
		  "    return y.var()",
		  "",
		  "def information_gain(y, mask, func=entropy):",
		  "  '''",
		  "  It returns the Information Gain of a variable given a loss function.",
		  "  y: target variable.",
		  "  mask: split choice.",
		  "  func: function to be used to calculate Information Gain in case os classification.",
		  "  '''",
		  "  ",
		  "  a = sum(mask)",
		  "  b = mask.shape[0] - a",
		  "  ",
		  "  if(a == 0 or b ==0): ",
		  "    ig = 0",
		  "  ",
		  "  else:",
		  "    if y.dtypes != 'O':",
		  "      ig = variance(y) - (a/(a+b)* variance(y[mask])) - (b/(a+b)*variance(y[-mask]))",
		  "    else:",
		  "      ig = func(y)-a/(a+b)*func(y[mask])-b/(a+b)*func(y[-mask])",
		  "  ",
		  "  return ig",
		  "",
		  "#############################",
		  "information_gain(data['obese'], data['Gender'] == 'Male')",
		  "###############################",
		  "import itertools",
		  "",
		  "def categorical_options(a):",
		  "  '''",
		  "  Creates all possible combinations from a Pandas Series.",
		  "  a: Pandas Series from where to get all possible combinations. ",
		  "  '''",
		  "  a = a.unique()",
		  "",
		  "  opciones = []",
		  "  for L in range(0, len(a)+1):",
		  "      for subset in itertools.combinations(a, L):",
		  "          subset = list(subset)",
		  "          opciones.append(subset)",
		  "",
		  "  return opciones[1:-1]",
		  "",
		  "def max_information_gain_split(x, y, func=entropy):",
		  "  '''",
		  "  Given a predictor & target variable, returns the best split, the error and the type of variable based on a selected cost function.",
		  "  x: predictor variable as Pandas Series.",
		  "  y: target variable as Pandas Series.",
		  "  func: function to be used to calculate the best split.",
		  "  '''",
		  "",
		  "  split_value = []",
		  "  ig = [] ",
		  "",
		  "  numeric_variable = True if x.dtypes != 'O' else False",
		  "",
		  "  # Create options according to variable type",
		  "  if numeric_variable:",
		  "    options = x.sort_values().unique()[1:]",
		  "  else: ",
		  "    options = categorical_options(x)",
		  "",
		  "  # Calculate ig for all values",
		  "  for val in options:",
		  "    mask =   x < val if numeric_variable else x.isin(val)",
		  "    val_ig = information_gain(y, mask, func)",
		  "    # Append results",
		  "    ig.append(val_ig)",
		  "    split_value.append(val)",
		  "",
		  "  # Check if there are more than 1 results if not, return False",
		  "  if len(ig) == 0:",
		  "    return(None,None,None, False)",
		  "",
		  "  else:",
		  "  # Get results with highest IG",
		  "    best_ig = max(ig)",
		  "    best_ig_index = ig.index(best_ig)",
		  "    best_split = split_value[best_ig_index]",
		  "    return(best_ig,best_split,numeric_variable, True)",
		  "",
		  "",
		  "weight_ig, weight_slpit, _, _ = max_information_gain_split(data['Weight'], data['obese'],)  ",
		  "",
		  "",
		  "print(",
		  "  \"The best split for Weight is when the variable is less than \",",
		  "  weight_slpit,\"\\nInformation Gain for that split is:\", weight_ig",
		  ")",
		  "##################################",
		  "data.drop('obese', axis= 1).apply(max_information_gain_split, y = data['obese'])",
		  "###################",
		  "def get_best_split(y, data):",
		  "  '''",
		  "  Given a data, select the best split and return the variable, the value, the variable type and the information gain.",
		  "  y: name of the target variable",
		  "  data: dataframe where to find the best split.",
		  "  '''",
		  "  masks = data.drop(y, axis= 1).apply(max_information_gain_split, y = data[y])",
		  "  if sum(masks.loc[3,:]) == 0:",
		  "    return(None, None, None, None)",
		  "",
		  "  else:",
		  "    # Get only masks that can be splitted",
		  "    masks = masks.loc[:,masks.loc[3,:]]",
		  "",
		  "    # Get the results for split with highest IG",
		  "    split_variable = max(masks)",
		  "    #split_valid = masks[split_variable][]",
		  "    split_value = masks[split_variable][1] ",
		  "    split_ig = masks[split_variable][0]",
		  "    split_numeric = masks[split_variable][2]",
		  "",
		  "    return(split_variable, split_value, split_ig, split_numeric)",
		  "",
		  "",
		  "def make_split(variable, value, data, is_numeric):",
		  "  '''",
		  "  Given a data and a split conditions, do the split.",
		  "  variable: variable with which make the split.",
		  "  value: value of the variable to make the split.",
		  "  data: data to be splitted.",
		  "  is_numeric: boolean considering if the variable to be splitted is numeric or not.",
		  "  '''",
		  "  if is_numeric:",
		  "    data_1 = data[data[variable] < value]",
		  "    data_2 = data[(data[variable] < value) == False]",
		  "",
		  "  else:",
		  "    data_1 = data[data[variable].isin(value)]",
		  "    data_2 = data[(data[variable].isin(value)) == False]",
		  "",
		  "  return(data_1,data_2)",
		  "",
		  "def make_prediction(data, target_factor):",
		  "  '''",
		  "  Given the target variable, make a prediction.",
		  "  data: pandas series for target variable",
		  "  target_factor: boolean considering if the variable is a factor or not",
		  "  '''",
		  "",
		  "  # Make predictions",
		  "  if target_factor:",
		  "    pred = data.value_counts().idxmax()",
		  "  else:",
		  "    pred = data.mean()",
		  "",
		  "  return pred",
		  "##########################################",
		  "def train_tree(data,y, target_factor, max_depth = None,min_samples_split = None, min_information_gain = 1e-20, counter=0, max_categories = 20):",
		  "  '''",
		  "  Trains a Decission Tree",
		  "  data: Data to be used to train the Decission Tree",
		  "  y: target variable column name",
		  "  target_factor: boolean to consider if target variable is factor or numeric.",
		  "  max_depth: maximum depth to stop splitting.",
		  "  min_samples_split: minimum number of observations to make a split.",
		  "  min_information_gain: minimum ig gain to consider a split to be valid.",
		  "  max_categories: maximum number of different values accepted for categorical values. High number of values will slow down learning process. R",
		  "  '''",
		  "",
		  "  # Check that max_categories is fulfilled",
		  "  if counter==0:",
		  "    types = data.dtypes",
		  "    check_columns = types[types == \"object\"].index",
		  "    for column in check_columns:",
		  "      var_length = len(data[column].value_counts()) ",
		  "      if var_length > max_categories:",
		  "        raise ValueError('The variable ' + column + ' has '+ str(var_length) + ' unique values, which is more than the accepted ones: ' +  str(max_categories))",
		  "",
		  "  # Check for depth conditions",
		  "  if max_depth == None:",
		  "    depth_cond = True",
		  "",
		  "  else:",
		  "    if counter < max_depth:",
		  "      depth_cond = True",
		  "",
		  "    else:",
		  "      depth_cond = False",
		  "",
		  "  # Check for sample conditions",
		  "  if min_samples_split == None:",
		  "    sample_cond = True",
		  "",
		  "  else:",
		  "    if data.shape[0] > min_samples_split:",
		  "      sample_cond = True",
		  "",
		  "    else:",
		  "      sample_cond = False",
		  "",
		  "  # Check for ig condition",
		  "  if depth_cond & sample_cond:",
		  "",
		  "    var,val,ig,var_type = get_best_split(y, data)",
		  "",
		  "    # If ig condition is fulfilled, make split ",
		  "    if ig is not None and ig >= min_information_gain:",
		  "",
		  "      counter += 1",
		  "",
		  "      left,right = make_split(var, val, data,var_type)",
		  "",
		  "      # Instantiate sub-tree",
		  "      split_type = \"<=\" if var_type else \"in\"",
		  "      question =   \"{} {}  {}\".format(var,split_type,val)",
		  "      # question = \"\\n\" + counter*\" \" + \"|->\" + var + \" \" + split_type + \" \" + str(val) ",
		  "      subtree = {question: []}",
		  "",
		  "",
		  "      # Find answers (recursion)",
		  "      yes_answer = train_tree(left,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)",
		  "",
		  "      no_answer = train_tree(right,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)",
		  "",
		  "      if yes_answer == no_answer:",
		  "        subtree = yes_answer",
		  "",
		  "      else:",
		  "        subtree[question].append(yes_answer)",
		  "        subtree[question].append(no_answer)",
		  "",
		  "    # If it doesn't match IG condition, make prediction",
		  "    else:",
		  "      pred = make_prediction(data[y],target_factor)",
		  "      return pred",
		  "",
		  "   # Drop dataset if doesn't match depth or sample conditions",
		  "  else:",
		  "    pred = make_prediction(data[y],target_factor)",
		  "    return pred",
		  "",
		  "  return subtree",
		  "",
		  "",
		  "max_depth = 5",
		  "min_samples_split = 20",
		  "min_information_gain  = 1e-5",
		  "",
		  "",
		  "decisiones = train_tree(data,'obese',True, max_depth,min_samples_split,min_information_gain)",
		  "",
		  "",
		  "decisiones",
		  "############################",
		  "",
		  "def clasificar_datos(observacion, arbol):",
		  "  question = list(arbol.keys())[0] ",
		  "",
		  "  if question.split()[1] == '<=':",
		  "",
		  "    if observacion[question.split()[0]] <= float(question.split()[2]):",
		  "      answer = arbol[question][0]",
		  "    else:",
		  "      answer = arbol[question][1]",
		  "",
		  "  else:",
		  "",
		  "    if observacion[question.split()[0]] in (question.split()[2]):",
		  "      answer = arbol[question][0]",
		  "    else:",
		  "      answer = arbol[question][1]",
		  "",
		  "  # If the answer is not a dictionary",
		  "  if not isinstance(answer, dict):",
		  "    return answer",
		  "  else:",
		  "    residual_tree = answer",
		  "    return clasificar_datos(observacion, answer)",
		  "",
		  ""
		],
		"description": "DT"
	  },

	  "KNNwithAccuracy": {
		"prefix": "KNNwithAccuracy",
		"body": [
		  "# Import necessary modules",
		  "from sklearn.neighbors import KNeighborsClassifier",
		  "from sklearn.model_selection import train_test_split",
		  "from sklearn.datasets import load_iris",
		  "",
		  "###################################33",
		  "",
		  "# Loading data",
		  "irisData = load_iris()",
		  " ",
		  "# Create feature and target arrays",
		  "X = irisData.data",
		  "y = irisData.target",
		  " ",
		  "# Split into training and test set",
		  "X_train, X_test, y_train, y_test = train_test_split(",
		  "             X, y, test_size = 0.2, random_state=42)",
		  " ",
		  "knn = KNeighborsClassifier(n_neighbors=7)",
		  " ",
		  "knn.fit(X_train, y_train)",
		  " ",
		  "# Calculate the accuracy of the model",
		  "print(knn.score(X_test, y_test))"
		],
		"description": "KNNwithAccuracy"
	  },

	  "KNNwithConfusion": {
		"prefix": "KNNwithConfusion",
		"body": [
		  "import numpy as np",
		  "import matplotlib.pyplot as plt",
		  "import pandas as pd",
		  "#######################33",
		  "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"",
		  "",
		  "# Assign colum names to the dataset",
		  "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']",
		  "",
		  "# Read dataset to pandas dataframe",
		  "dataset = pd.read_csv(url, names=names)",
		  "###########################################",
		  "dataset.head()",
		  "#########################33",
		  "X = dataset.iloc[:, :-1].values",
		  "y = dataset.iloc[:, 4].values",
		  "",
		  "########################3",
		  "from sklearn.model_selection import train_test_split",
		  "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)",
		  "############################",
		  "from sklearn.preprocessing import StandardScaler",
		  "scaler = StandardScaler()",
		  "scaler.fit(X_train)",
		  "",
		  "X_train = scaler.transform(X_train)",
		  "X_test = scaler.transform(X_test)",
		  "##############################3",
		  "from sklearn.neighbors import KNeighborsClassifier",
		  "classifier = KNeighborsClassifier(n_neighbors=5)",
		  "classifier.fit(X_train, y_train)",
		  "#####################3",
		  "y_pred = classifier.predict(X_test)",
		  "##############################",
		  "from sklearn.metrics import classification_report, confusion_matrix",
		  "print(confusion_matrix(y_test, y_pred))",
		  "print(classification_report(y_test, y_pred))",
		  "##############################",
		  "error = []",
		  "",
		  "# Calculating error for K values between 1 and 40",
		  "for i in range(1, 40):",
		  "    knn = KNeighborsClassifier(n_neighbors=i)",
		  "    knn.fit(X_train, y_train)",
		  "    pred_i = knn.predict(X_test)",
		  "    error.append(np.mean(pred_i != y_test))",
		  "###################################3",
		  "plt.figure(figsize=(12, 6))",
		  "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',",
		  "         markerfacecolor='blue', markersize=10)",
		  "plt.title('Error Rate K Value')",
		  "plt.xlabel('K Value')",
		  "plt.ylabel('Mean Error')"
		],
		"description": "KNNwithConfusion"
	  },

	  "SVM": {
		"prefix": "SVM",
		"body": [
		  "import numpy as np",
		  "import pandas as pd",
		  "from sklearn import svm",
		  "import matplotlib.pyplot as plt",
		  "%matplotlib inline",
		  "##########################################",
		  "data = pd.read_csv('https://raw.githubusercontent.com/LearnPythonWithRune/MachineLearningWithPython/main/jupyter/final/files/gender.csv')",
		  "data.head()",
		  "##########################################",
		  "data['Class'] = data['Gender'].apply(lambda x: 'r' if x == 'F' else 'b')",
		  "data.head()",
		  "#########################################",
		  "data = data.iloc[:25]",
		  "fig, ax = plt.subplots()",
		  "ax.scatter(x=data['Height'], y=data['Hair length'], c=data['Class'])",
		  "ax.axhline(20)",
		  "x = np.array([150, 190])",
		  "ax.plot(x, x - 145, c='y')",
		  "ax.plot(x, 2*x - 310, c='g')",
		  "###########################################3",
		  "X = data[['Height', 'Hair length']]",
		  "y = data['Gender']",
		  "y = np.array([0 if gender == 'M' else 1 for gender in y])",
		  "clf = svm.SVC(kernel='linear')",
		  "clf.fit(X, y)",
		  "###################################",
		  "X_test = np.random.rand(10000, 2)",
		  "X_test = X_test*(50, 120) + (150, 0)",
		  "",
		  "y_pred = clf.predict(X_test)",
		  "     ",
		  "",
		  "fig, ax = plt.subplots()",
		  "",
		  "ax.scatter(x=X_test[:,0], y=X_test[:,1], c=y_pred, alpha=.25)",
		  "y_color = ['r' if value == 0 else 'b' for value in y]",
		  "ax.scatter(x=X['Height'], y=X['Hair length'], c=y_color)",
		  "#####################################3",
		  ""
		],
		"description": "SVM"
	  },

	  "KMeans": {
		"prefix": "KMeans",
		"body": [
		  "import pandas as pd",
		  "import numpy as np",
		  "from sklearn import datasets",
		  "from sklearn.cluster import KMeans",
		  "import matplotlib.pyplot as plt",
		  "import matplotlib.patches as mpatches",
		  "import sklearn.metrics as sm",
		  "%matplotlib inline",
		  "##############################",
		  "",
		  "iris = datasets.load_iris()",
		  "print (iris.target_names)",
		  "##########################3",
		  "",
		  "print (iris.target)",
		  "",
		  "##################################3",
		  "x = pd.DataFrame(iris.data, columns=['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width'])",
		  "y = pd.DataFrame(iris.target, columns=['Target'])",
		  "x.head()",
		  "",
		  "####################################",
		  "y.head()",
		  "",
		  "##############################",
		  "plt.figure(figsize=(12,3))",
		  "colors = np.array(['red', 'green', 'blue'])",
		  "iris_targets_legend = np.array(iris.target_names)",
		  "red_patch = mpatches.Patch(color='red', label='Setosa')",
		  "green_patch = mpatches.Patch(color='green', label='Versicolor')",
		  "blue_patch = mpatches.Patch(color='blue', label='Virginica')",
		  "",
		  "",
		  "plt.subplot(1, 2, 1)",
		  "plt.scatter(x['Sepal Length'], x['Sepal Width'], c=colors[y['Target']])",
		  "plt.title('Sepal Length vs Sepal Width')",
		  "plt.legend(handles=[red_patch, green_patch, blue_patch])",
		  "",
		  "plt.subplot(1,2,2)",
		  "plt.scatter(x['Petal Length'], x['Petal Width'], c= colors[y['Target']])",
		  "plt.title('Petal Length vs Petal Width')",
		  "plt.legend(handles=[red_patch, green_patch, blue_patch])",
		  "",
		  "##################################",
		  "",
		  "iris_k_mean_model = KMeans(n_clusters=3)",
		  "iris_k_mean_model.fit(x)",
		  "",
		  "#############################",
		  "print (iris_k_mean_model.labels_)",
		  "",
		  "################################",
		  "print (iris_k_mean_model.cluster_centers_)",
		  "",
		  "################################",
		  "plt.figure(figsize=(12,3))",
		  "colors = np.array(['red', 'green', 'blue'])",
		  "predictedY = np.choose(iris_k_mean_model.labels_, [1, 0, 2]).astype(np.int64)",
		  "plt.subplot(1, 2, 1)",
		  "plt.scatter(x['Petal Length'], x['Petal Width'], c=colors[y['Target']])",
		  "plt.title('Before classification')",
		  "plt.legend(handles=[red_patch, green_patch, blue_patch])",
		  "plt.subplot(1, 2, 2)",
		  "plt.scatter(x['Petal Length'], x['Petal Width'], c=colors[predictedY])",
		  "plt.title(\"Model's classification\")",
		  "plt.legend(handles=[red_patch, green_patch, blue_patch])",
		  "",
		  "#######################################",
		  "sm.accuracy_score(predictedY, y['Target'])",
		  "",
		  "################################",
		  "sm.confusion_matrix(predictedY, y['Target'])",
		  ""
		],
		"description": "KMeans"
	  },




	  "SARSA": {
		"prefix": "SARSA",
		"body": [
			"import numpy as np",
			"import gym",
			"",
			"# FrozenLake-v0 gym environment",
			"env = gym.make('FrozenLake-v1')",
			"",
			"# Parameters",
			"epsilon = 0.9",
			"total_episodes = 10000",
			"max_steps = 100",
			"alpha = 0.05",
			"gamma = 0.95",
			"  ",
			"#Initializing the Q-vaue",
			"Q = np.zeros((env.observation_space.n, env.action_space.n))",
			"",
			"# Function to choose the next action with episolon greedy",
			"def choose_action(state):",
			"    action=0",
			"    if np.random.uniform(0, 1) < epsilon:",
			"        action = env.action_space.sample()",
			"    else:",
			"        action = np.argmax(Q[state, :])",
			"    return action",
			"    ",
			"#Initializing the reward",
			"reward=0",
			"  ",
			"# Starting the SARSA learning",
			"for episode in range(total_episodes):",
			"    t = 0",
			"    state1 = env.reset()",
			"    action1 = choose_action(state1)",
			"  ",
			"    while t < max_steps:",
			"        # Visualizing the training",
			"#         env.render()",
			"          ",
			"        # Getting the next state",
			"        state2, reward, done, info = env.step(action1)",
			"  ",
			"        #Choosing the next action",
			"        action2 = choose_action(state2)",
			"          ",
			"        #Learning the Q-value",
			"        Q[state1, action1] = Q[state1, action1] + alpha * (reward + gamma * Q[state2, action2] - Q[state1, action1])",
			"  ",
			"        state1 = state2",
			"        action1 = action2",
			"          ",
			"        #Updating the respective vaLues",
			"        t += 1",
			"        reward += 1",
			"          ",
			"        #If at the end of learning process",
			"        if done:",
			"            break",
			"            ",
			"#Evaluating the performance",
			"print (\"Performace : \", reward/total_episodes)",
			"  ",
			"#Visualizing the Q-matrix",
			"print(Q)"
		],
		"description": "SARSA"
	  },

	  "RL": {
		"prefix": "RL",
		"body": [
		  "!pip install stable-baselines3",
		  "!pip install pyglet",
		  "############################",
		  "import gym ",
		  "from stable_baselines3 import PPO",
		  "from stable_baselines3.common.vec_env import DummyVecEnv",
		  "from stable_baselines3.common.evaluation import evaluate_policy",
		  "",
		  "###########################",
		  "",
		  "environment_name = \"CartPole-v0\"",
		  "env = gym.make(environment_name)",
		  "episodes = 5",
		  "for episode in range(1, episodes+1):",
		  "    state = env.reset()",
		  "    done = False",
		  "    score = 0 ",
		  "    ",
		  "    while not done:",
		  "        #env.render()",
		  "        action = env.action_space.sample()",
		  "        n_state, reward, done, info = env.step(action)",
		  "        score+=reward",
		  "    print('Episode:{} Score:{}'.format(episode, score))",
		  "env.close()",
		  "",
		  "#########################",
		  "env = gym.make(environment_name)",
		  "env = DummyVecEnv([lambda: env])",
		  "model = PPO('MlpPolicy', env, verbose = 1)",
		  "model.learn(total_timesteps=20000)",
		  "",
		  "",
		  "##########################",
		  "",
		  "obs = env.reset()",
		  "while True:",
		  "    action, _states = model.predict(obs)",
		  "    obs, rewards, done, info = env.step(action)",
		  "    #env.render()",
		  "    if done: ",
		  "        print('info', info)",
		  "        break",
		  "env.close()",
		  "",
		  ""
		],
		"description": "RL"
	  },

	  "QLearning": {
		"prefix": "QLearning",
		"body": [
		  "#another way for Q-learning ",
		  "",
		  "import numpy as np",
		  "import gym",
		  "",
		  "# Create the FrozenLake-v0 environment",
		  "env = gym.make('FrozenLake-v1')",
		  "",
		  "# Set the hyperparameters",
		  "num_episodes = 10000",
		  "max_steps = 100",
		  "alpha = 0.1",
		  "gamma = 0.99",
		  "epsilon = 1.0",
		  "epsilon_min = 0.01",
		  "epsilon_decay = 0.99",
		  "",
		  "# Initialize the Q-table",
		  "num_states = env.observation_space.n",
		  "num_actions = env.action_space.n",
		  "Q = np.zeros((num_states, num_actions))",
		  "",
		  "# Define the epsilon-greedy policy",
		  "def epsilon_greedy_policy(state, epsilon):",
		  "    if np.random.rand() < epsilon:",
		  "        # Take a random action",
		  "        action = env.action_space.sample()",
		  "    else:",
		  "        # Choose the best action from the Q-table",
		  "        action = np.argmax(Q[state, :])",
		  "    return action",
		  "",
		  "# Loop over episodes",
		  "for episode in range(num_episodes):",
		  "    # Reset the environment and get the initial state",
		  "    state = env.reset()",
		  "    ",
		  "    # Choose the initial action using the epsilon-greedy policy",
		  "    action = epsilon_greedy_policy(state, epsilon)",
		  "    ",
		  "    # Initialize the total reward for the episode",
		  "    total_reward = 0",
		  "    ",
		  "    # Loop over steps within this episode",
		  "    for t in range(max_steps):",
		  "        # Take the chosen action and observe the next state and reward",
		  "        next_state, reward, done, info = env.step(action)",
		  "        ",
		  "        # Choose the next action using the epsilon-greedy policy",
		  "        next_action = epsilon_greedy_policy(next_state, epsilon)",
		  "        ",
		  "        # Update the Q-table",
		  "        td_error = reward + gamma * Q[next_state, next_action] - Q[state, action]",
		  "        Q[state, action] += alpha * td_error",
		  "        ",
		  "        # Update the state, action, and total reward",
		  "        state = next_state",
		  "        action = next_action",
		  "        total_reward += reward",
		  "        ",
		  "        # If the episode is complete, break out of the loop",
		  "        if done:",
		  "            break",
		  "    ",
		  "    # Decay the epsilon value for the next episode",
		  "    epsilon = max(epsilon_min, epsilon * epsilon_decay)",
		  "    ",
		  "    # Print the total reward for this episode",
		  "    print(f\"Episode {episode}: Total reward = {total_reward}\")",
		  "    ",
		  "# Print the final Q-table",
		  "print(\"Final Q-table:\")",
		  "print(Q)",
		  ""
		],
		"description": "QLearning"
	  },

	  "RL_TaxiV3": {
		"prefix": "RL_TaxiV3",
		"body": [
		  "",
		  "import gym",
		  "",
		  "# Create the taxi environment",
		  "env = gym.make('Taxi-v3')",
		  "env.render()",
		  "##########################################33",
		  "env.reset() # reset environment to a new, random state",
		  "env.render()",
		  "",
		  "print(\"Action Space {}\".format(env.action_space))",
		  "print(\"State Space {}\".format(env.observation_space))",
		  "",
		  "##############################################",
		  "",
		  "",
		  "",
		  "# Initialize the Q-table with zeros",
		  "Q = np.zeros([env.observation_space.n, env.action_space.n])",
		  "",
		  "# Set the hyperparameters",
		  "alpha = 0.1",
		  "gamma = 0.6",
		  "epsilon = 0.1",
		  "",
		  "# Run the Q-learning algorithm for 5000 episodes",
		  "for episode in range(5000):",
		  "    # Reset the environment for each episode",
		  "    state = env.reset()",
		  "    done = False",
		  "    ",
		  "    while not done:",
		  "        # Epsilon-greedy strategy to choose the next action",
		  "        if np.random.uniform() < epsilon:",
		  "            action = env.action_space.sample()",
		  "        else:",
		  "            action = np.argmax(Q[state, :])",
		  "        ",
		  "        # Perform the action and observe the new state and reward",
		  "        next_state, reward, done, info = env.step(action)",
		  "        ",
		  "        # Update the Q-table using the Q-learning formula",
		  "        Q[state, action] = (1 - alpha) * Q[state, action] + alpha * (reward + gamma * np.max(Q[next_state, :]))",
		  "        ",
		  "        # Update the current state",
		  "        state = next_state",
		  "    ",
		  "# Test the agent",
		  "state = env.reset()",
		  "done = False",
		  "",
		  "while not done:",
		  "    # Choose the action with the highest Q-value",
		  "    action = np.argmax(Q[state, :])",
		  "    ",
		  "    # Perform the action and observe the new state and reward",
		  "    next_state, reward, done, info = env.step(action)",
		  "    ",
		  "    # Update the current state",
		  "    state = next_state",
		  "    ",
		  "# Print the final state and reward",
		  "print(f\"Final state: {state}\")",
		  "print(f\"Final reward: {reward}\")",
		  ""
		],
		"description": "RL_TaxiV3"
	  }





	  


	
}